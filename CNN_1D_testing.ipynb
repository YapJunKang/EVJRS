{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, Dropout, Conv2d, MaxPool2d\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import gurobipy as gb\n",
    "from gurobipy import GRB\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set CUDA_VISIBLE_DEVICES=0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dir = os.path.join(os.getcwd(), \"dataGeneration/preprocessed_data_test\")\n",
    "\n",
    "X_test = np.load(os.path.join(train_test_dir, \"X_test.npy\"))\n",
    "y_test = np.load(os.path.join(train_test_dir, \"y_test.npy\"))\n",
    "index_test = np.load(os.path.join(train_test_dir, \"indices_test.npy\")).astype(\"int64\")\n",
    "\n",
    "solTime_test = np.load(os.path.join(train_test_dir, \"solTime_test.npy\"))\n",
    "objVal_test = np.load(os.path.join(train_test_dir, \"objVal_test.npy\"))\n",
    "schedule_test = np.load(os.path.join(train_test_dir, \"schedule_test.npy\")).astype(\"int32\")\n",
    "model_test = np.load(os.path.join(train_test_dir, \"model_test.npy\")).astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.transpose(X_test, (0,1,3,2))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_test.dtype)\n",
    "print(y_test.shape)\n",
    "print(y_test.dtype)\n",
    "print(index_test.shape)\n",
    "print(index_test.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = X_test.shape[2]\n",
    "col = X_test.shape[3]\n",
    "\n",
    "out_channels = y_test.shape[-1]\n",
    "nbScen = X_test.shape[1]\n",
    "\n",
    "print(in_channels, col, out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.hidden_ch = 64\n",
    "        self.dp = 0.1\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, self.hidden_ch, 11, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dp),\n",
    "            nn.MaxPool1d(5, stride=1, padding=0),\n",
    "\n",
    "            nn.Conv1d(self.hidden_ch, self.hidden_ch*2, 7, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dp),\n",
    "            nn.MaxPool1d(5, stride=1, padding=0),\n",
    "\n",
    "            nn.Conv1d(self.hidden_ch*2, self.hidden_ch, 3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dp),\n",
    "            nn.MaxPool1d(5, stride=1, padding=0),\n",
    "        )\n",
    "        \n",
    "        n_channels = self.feature_extractor(torch.zeros(1, in_channels, col)).size(-1)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.MaxPool1d(n_channels), # GAP\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.hidden_ch, self.hidden_ch*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dp),\n",
    "            nn.Linear(self.hidden_ch*2, self.hidden_ch*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dp),\n",
    "            nn.Linear(self.hidden_ch*2, out_channels),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        out = self.classifier(features)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'batch_size' : 8, # Num samples to average over for gradient updates\n",
    "        'EPOCHS' : 500, # Num times to iterate over the entire dataset\n",
    "        'LEARNING_RATE' : 5e-4, # Learning rate for the optimizer\n",
    "        'WEIGHT_DECAY' : 1e-4, # Weight decay parameter for the Adam optimizer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class coordinationDataset(TensorDataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(coordinationDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "        \n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        y_tensor = torch.round(torch.tensor(y, dtype=torch.float32))\n",
    "\n",
    "        return X_tensor, y_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = coordinationDataset(X_test, y_test)\n",
    "\n",
    "print(test_dataset.X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork()\n",
    "\n",
    "batch_size = config['batch_size']\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=config[\"LEARNING_RATE\"])\n",
    "total_steps = len(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetric_loss(predict, target, gamma_neg=0.3, gamma_pos=0, clip=0.0, eps=1e-8, disable_torch_grad_focal_loss=True):\n",
    "\n",
    "    \"\"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: input logits\n",
    "    y: targets (multi-label binarized vector)\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculating Probabilities\n",
    "    x_sigmoid = predict\n",
    "    xs_pos = x_sigmoid\n",
    "    xs_neg = 1 - x_sigmoid\n",
    "\n",
    "    # Asymmetric Clipping\n",
    "    if clip is not None and clip > 0:\n",
    "        xs_neg = (xs_neg + clip).clamp(max=1)\n",
    "\n",
    "    # Basic CE calculation\n",
    "    los_pos = target * torch.log(xs_pos.clamp(min=eps))\n",
    "    los_neg = (1 - target) * torch.log(xs_neg.clamp(min=eps))\n",
    "    loss = los_pos + los_neg\n",
    "\n",
    "    # Asymmetric Focusing\n",
    "    if gamma_neg > 0 or gamma_pos > 0:\n",
    "        if disable_torch_grad_focal_loss:\n",
    "            torch.set_grad_enabled(False)\n",
    "        pt0 = xs_pos * target\n",
    "        pt1 = xs_neg * (1 - target)  # pt = p if t > 0 else 1-p\n",
    "        pt = pt0 + pt1\n",
    "        one_sided_gamma = gamma_pos * target + gamma_neg * (1 - target)\n",
    "        one_sided_w = torch.pow(1 - pt, one_sided_gamma)\n",
    "        if disable_torch_grad_focal_loss:\n",
    "            torch.set_grad_enabled(True)\n",
    "        loss *= one_sided_w\n",
    "\n",
    "    return -loss.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "interval = 20\n",
    "\n",
    "net = NeuralNetwork()\n",
    "net.load_state_dict(torch.load(os.path.join(os.getcwd(), f\"ML_Model/CNN_1D_coordination_{interval}.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test number of feasible solutions\n",
    "# test the model on the test set\n",
    "net.eval()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing of bit accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 0.5\n",
    "\n",
    "one_accuracy = []\n",
    "zero_accuracy = []\n",
    "bit_accuracy = []\n",
    "running_loss = 0\n",
    "mean_one = []\n",
    "mean_zero = []\n",
    "\n",
    "for j, data in enumerate(test_loader):\n",
    "    \n",
    "    net.eval()\n",
    "    inputs_all, labels_all = data\n",
    "\n",
    "    # do a for loop to perform perdiction for each scenario\n",
    "    output_append = torch.tensor([], device=device)\n",
    "    gt_append = torch.tensor([], device=device)\n",
    "\n",
    "    for x in range(nbScen):\n",
    "        \n",
    "        inputs, labels = inputs_all[:,x,:,:].to(device), labels_all[:,x,:,].to(device)       \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        output_append = torch.concat((output_append, outputs),dim=1)\n",
    "        gt_append = torch.concat((gt_append, labels),dim=1)\n",
    "\n",
    "    output_append = output_append.reshape(-1,)\n",
    "    gt_append = gt_append.reshape(-1,)\n",
    "\n",
    "    loss_fn = nn.BCELoss()\n",
    "    loss = loss_fn(output_append, gt_append)\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    # start testing\n",
    "    outputs_percent = output_append\n",
    "    output_append = torch.where(output_append >= thres, torch.ceil(output_append), torch.floor(output_append)).reshape(-1,)\n",
    "    # outputs = torch.round(outputs)\n",
    "\n",
    "    one_labels = torch.where(gt_append == 1)\n",
    "    zero_labels = torch.where(gt_append == 0)\n",
    "    \n",
    "    one_outputs = output_append[one_labels]\n",
    "    zero_outputs = output_append[zero_labels]\n",
    "\n",
    "    one_acc = 1 - torch.sum(torch.abs(1 - one_outputs)) / one_outputs.shape[0] # 1 minus percentage of error\n",
    "    zero_acc = 1 - torch.sum(torch.abs(0 - zero_outputs)) / zero_outputs.shape[0]\n",
    "    bit_acc = 1 - torch.sum(torch.abs(output_append - gt_append)) / gt_append.shape[0]\n",
    "\n",
    "    one_accuracy.append(one_acc.cpu().detach().numpy())\n",
    "    zero_accuracy.append(zero_acc.cpu().detach().numpy())\n",
    "    bit_accuracy.append(bit_acc.cpu().detach().numpy())\n",
    "\n",
    "    # mean acc\n",
    "    id_1 = torch.where(output_append == 1)\n",
    "    id_0 = torch.where(output_append == 0)\n",
    "\n",
    "    p_1 = outputs_percent[id_1]\n",
    "    p_0 = outputs_percent[id_0]\n",
    "\n",
    "\n",
    "    y_1 = gt_append[id_1]\n",
    "    y_0 = gt_append[id_0]\n",
    "\n",
    "    y_1_1 = torch.where(y_1 == 1)\n",
    "    y_1_0 = torch.where(y_1 == 0)\n",
    "    y_0_1 = torch.where(y_0 == 1)\n",
    "    y_0_0 = torch.where(y_0 == 0)\n",
    "\n",
    "    avg_1 = torch.mean(torch.cat((p_1[y_1_1], torch.ones(y_1_0[0].shape[0]).to(device) - p_1[y_1_0])))\n",
    "    avg_0 = torch.mean(torch.cat((p_0[y_0_1], torch.ones(y_0_0[0].shape[0]).to(device) - p_0[y_0_0])))\n",
    "\n",
    "    # avg_1 = torch.mean(torch.cat((p_1[y_1_1],  p_1[y_1_0])))\n",
    "    # avg_0 = torch.mean(torch.cat((p_0[y_0_1], p_0[y_0_0])))\n",
    "\n",
    "    # avg_1 = torch.mean(p_1[y_1_1])\n",
    "    # avg_0 = torch.mean(p_0[y_0_1])\n",
    "\n",
    "    # avg_1 = torch.mean(p_1[y_1_0])\n",
    "    # avg_0 = torch.mean(p_0[y_0_1])\n",
    "\n",
    "    mean_one.append(avg_1.cpu().detach().numpy())\n",
    "    mean_zero.append(avg_0.cpu().detach().numpy())\n",
    "\n",
    "print(\"Average one bit accuracy\", np.mean(one_accuracy))\n",
    "print(\"Average zero bit accuracy\", np.mean(zero_accuracy))\n",
    "print(\"Average bit accuracy\", np.mean(bit_accuracy))\n",
    "print('Loss:', running_loss / len(test_loader))\n",
    "print(np.mean(mean_one), np.mean(mean_zero))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for baseline solving speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gurobi_env = gb.Env()\n",
    "gurobi_env.setParam(\"OutputFlag\", 0)\n",
    "    \n",
    "# loop through all test models and calculate average optimization time\n",
    "opt_time = []\n",
    "opt_val = []\n",
    "opt_ones = []\n",
    "for i, _ in enumerate(model_test):\n",
    "    \n",
    "    runtime = solTime_test[i]\n",
    "    obj = objVal_test[i]\n",
    "    \n",
    "    print(\"Optimization time for model \", i, \": \", runtime)\n",
    "    print(\"Optimization Value for model \", i, \": \", obj)\n",
    "    \n",
    "    opt_time.append(runtime)\n",
    "    opt_val.append(obj)\n",
    "\n",
    "    nbEV = np.max(schedule_test[i][:,0]) + 1\n",
    "    binary_vars = y_test[i]\n",
    "\n",
    "    opt_ones.append(np.count_nonzero(np.round(binary_vars)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dict = {\n",
    "    \"opt_time\": opt_time,\n",
    "    \"opt_val\": opt_val,\n",
    "    \"opt_ones\": opt_ones\n",
    "}\n",
    "\n",
    "result_path = os.path.join(os.getcwd(), f\"Results\")\n",
    "with open(os.path.join(result_path, \"opt_test.pkl\"), 'wb') as f:\n",
    "    pickle.dump(opt_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = os.path.join(os.getcwd(), f\"Results\")\n",
    "with open(os.path.join(result_path, \"opt_test.pkl\"), 'rb') as f:\n",
    "    opt_dict = pickle.load(f)\n",
    "\n",
    "opt_time = opt_dict[\"opt_time\"]\n",
    "opt_val = opt_dict[\"opt_val\"]\n",
    "opt_ones = opt_dict[\"opt_ones\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten opt_time\n",
    "print(\"Average optimization time: \", np.mean(opt_time))\n",
    "opt_time_baseline = np.mean(opt_time)\n",
    "# flatten opt_time\n",
    "print(\"Average optimization value: \", np.mean(opt_val))\n",
    "opt_val_baseline = np.mean(opt_val)\n",
    "print(\"Number of ones: \", opt_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in paramaeters\n",
    "data_dir = os.path.join(os.getcwd(), 'systemData')\n",
    "EV_routes = pd.read_csv(os.path.join(data_dir, 'EV_routes.csv')).to_numpy()\n",
    "bus_params = pd.read_csv(os.path.join(data_dir, 'bus_params.csv')).to_numpy()\n",
    "# EV_schedules = pd.read_csv(os.path.join(data_dir, 'EV_schedules.csv')).to_numpy().astype(\"int32\")\n",
    "\n",
    "nbTime, nbBus, nbRoute = 48, bus_params.shape[0], EV_routes.shape[0]\n",
    "traffic = np.zeros(nbTime-1)\n",
    "traffic[14:20] = 1      # from 7-10am \n",
    "traffic[32:40] = 1      # from 4-8pm\n",
    "\n",
    "charging_station = np.squeeze(pd.read_csv(os.path.join(data_dir, 'cs_params_variable.csv')).to_numpy())\n",
    "non_charging_station = np.array([i for i in range(nbBus) if i not in charging_station])\n",
    "nbCS = len(charging_station)\n",
    "\n",
    "normal_nodes =  list(charging_station) + list(range(101,108))\n",
    "virtual_nodes = list(range(201,205))\n",
    "congest_nodes = list(range(301,324))\n",
    "\n",
    "always_arc, normal_arc, congest_arc = [], [], []\n",
    "\n",
    "for r in range(nbRoute):\n",
    "    if (EV_routes[r,1] in (normal_nodes+virtual_nodes)) and (EV_routes[r,2] in (normal_nodes+virtual_nodes)) and (EV_routes[r,1] != EV_routes[r,2]):\n",
    "        normal_arc.append(r)\n",
    "    elif (EV_routes[r,1] in (normal_nodes+virtual_nodes)) and (EV_routes[r,2] in congest_nodes):\n",
    "        congest_arc.append(r)\n",
    "    else:\n",
    "        always_arc.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_EV= 100\n",
    "var_per_EV = (nbRoute*(nbTime-1) + nbCS*nbTime*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing equality constraint with feasibility check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "gurobi_env = gb.Env()\n",
    "gurobi_env.setParam(\"OutputFlag\", 0)\n",
    "\n",
    "# loop through all test models and calculate average optimization time\n",
    "opt_time_feas = []\n",
    "opt_val_feas = []\n",
    "opt_ones_feas = []\n",
    "opt_utilized_feas = []\n",
    "for i, x in enumerate(model_test):\n",
    "    # if i == 28:\n",
    "\n",
    "    path = os.path.join(os.getcwd(), \"dataGeneration/model_test\")\n",
    "\n",
    "    model = gb.read(os.path.join(path, f\"coordination_{x}.mps\"), env=gurobi_env)\n",
    "    model.setParam(\"OutputFlag\", 0)\n",
    "    model.setParam(\"TimeLimit\", 120*60)\n",
    "\n",
    "    ################# timing the first code block #####################\n",
    "    start = time.time()\n",
    "\n",
    "    # deep learning prediciton\n",
    "    output_append = torch.tensor([], device=device)\n",
    "    gt_append = torch.tensor([], device=device)\n",
    "\n",
    "    for s in range(nbScen):\n",
    "        inputs = torch.tensor(np.expand_dims(test_dataset.X[i][s], axis=0), dtype=torch.float32) \n",
    "        inputs = inputs.to(device)    \n",
    "        outputs = net(inputs) \n",
    "\n",
    "        # extract correct amount of binary before concat\n",
    "        nbEV = np.max(schedule_test[i][:,0]) + 1\n",
    "        outs = outputs[:,0:var_per_EV*nbEV]\n",
    "        gts = torch.tensor(y_test[i,s,0:var_per_EV*nbEV], device=device).reshape(1,-1)\n",
    "\n",
    "        output_append = torch.concat((output_append, outs),dim=1)\n",
    "        gt_append = torch.concat((gt_append, gts),dim=1)\n",
    "\n",
    "    output_append = output_append.reshape(-1,)\n",
    "    gt_append = gt_append.reshape(-1,)\n",
    "\n",
    "    ################## end #########################\n",
    "\n",
    "    y_pred_binary =  (output_append).reshape(-1,).cpu().detach().numpy()\n",
    "    # y_pred_binary = gt_append.reshape(-1,).cpu().detach().numpy()\n",
    "\n",
    "    modelVars = model.getVars()\n",
    "\n",
    "    # get correct amount of index\n",
    "    bin_id = index_test[i][0:var_per_EV*nbEV*nbScen].reshape(-1,)\n",
    "\n",
    "    one_threshold = (np.mean(mean_one))\n",
    "    zero_threshold = (1-np.mean(mean_zero))\n",
    "\n",
    "    # use equality constraint from here on\n",
    "    for j in range(len(y_pred_binary)):\n",
    "        if (y_pred_binary[j] >= one_threshold or y_pred_binary[j] <= zero_threshold):\n",
    "            modelVars[bin_id[j]].setAttr(\"LB\", round(y_pred_binary[j]))\n",
    "            modelVars[bin_id[j]].setAttr(\"UB\", round(y_pred_binary[j]))\n",
    "            \n",
    "    end = time.time()\n",
    "    runtime1 = end - start\n",
    "\n",
    "    opt_ones_feas.append(np.count_nonzero(y_pred_binary >= one_threshold))\n",
    "    opt_utilized_feas.append(np.count_nonzero(y_pred_binary >= one_threshold)+  np.count_nonzero(y_pred_binary <= zero_threshold))\n",
    "\n",
    "    ################# timing the second code block #####################\n",
    "    start = time.time()\n",
    "\n",
    "    model.optimize()\n",
    "\n",
    "    end = time.time()\n",
    "    runtime2 = end - start\n",
    "    runtime = runtime1 + runtime2\n",
    "    ################## end #########################\n",
    "    \n",
    "    try:\n",
    "        print(\"Optimization time for model \", i, \": \", model.ObjVal)\n",
    "        print(\"Optimization value for model \", i, \": \", runtime)\n",
    "        opt_time_feas.append(runtime)\n",
    "        opt_val_feas.append(model.ObjVal) \n",
    "\n",
    "    except:\n",
    "        print(\"infeasible, reoptimising\")\n",
    "\n",
    "        model.dispose()\n",
    "\n",
    "        ###### reset model and re-fix the values\n",
    "        model = gb.read(os.path.join(path, f\"coordination_{x}.mps\"), env=gurobi_env)\n",
    "        model.setParam(\"OutputFlag\", 0)\n",
    "        model.setParam(\"TimeLimit\", 120*60)\n",
    "\n",
    "        ################# timing the code block #####################\n",
    "        start = time.time()\n",
    "\n",
    "        modelVars = model.getVars()\n",
    "\n",
    "        # get correct amount of index\n",
    "        bin_id = index_test[i][0:var_per_EV*nbEV*nbScen].reshape(-1,)\n",
    "\n",
    "        one_threshold = (np.mean(mean_one)) + 0.1\n",
    "        zero_threshold = (1-np.mean(mean_zero))\n",
    "\n",
    "        # use equality constraint from here on\n",
    "        for j in range(len(y_pred_binary)):\n",
    "            if (y_pred_binary[j] >= one_threshold or y_pred_binary[j] <= zero_threshold):\n",
    "                modelVars[bin_id[j]].setAttr(\"LB\", round(y_pred_binary[j]))\n",
    "                modelVars[bin_id[j]].setAttr(\"UB\", round(y_pred_binary[j]))\n",
    "                \n",
    "        end = time.time()\n",
    "        runtime3 = end - start\n",
    "        \n",
    "        opt_ones_feas.append(np.count_nonzero(y_pred_binary >= one_threshold))\n",
    "        opt_utilized_feas.append(np.count_nonzero(y_pred_binary >= one_threshold)+  np.count_nonzero(y_pred_binary <= zero_threshold))\n",
    "\n",
    "        ################# timing the second code block #####################\n",
    "        start = time.time()\n",
    "\n",
    "        model.optimize()\n",
    "\n",
    "        end = time.time()\n",
    "        runtime4 = end - start\n",
    "        runtime = runtime + runtime3 + runtime4 \n",
    "\n",
    "        try:\n",
    "            print(\"Optimization time for model \", i, \": \", model.ObjVal)\n",
    "            print(\"Optimization value for model \", i, \": \", runtime)\n",
    "            opt_time_feas.append(runtime)\n",
    "            opt_val_feas.append(model.ObjVal) \n",
    "        except:\n",
    "            print('infeasible')\n",
    "            opt_time_feas.append(0)\n",
    "            opt_val_feas.append(0) \n",
    "\n",
    "    \n",
    "    model.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dict_feas = {\n",
    "    \"opt_time\": opt_time_feas,\n",
    "    \"opt_val\": opt_val_feas,\n",
    "    \"opt_ones\": opt_ones_feas,\n",
    "    \"opt_utilized\": opt_utilized_feas\n",
    "}\n",
    "\n",
    "result_path = os.path.join(os.getcwd(), f\"Results\")\n",
    "with open(os.path.join(result_path, f\"CNN_1D_{interval}_test_opt_feas.pkl\"), 'wb') as f:\n",
    "    pickle.dump(opt_dict_feas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"CNN_1D_{interval}_test_opt_feas.pkl\"), 'rb') as f:\n",
    "    opt_dict_feas = pickle.load(f)\n",
    "\n",
    "opt_time_feas = opt_dict_feas[\"opt_time\"]\n",
    "opt_val_feas = opt_dict_feas[\"opt_val\"]\n",
    "opt_ones_feas = opt_dict_feas[\"opt_ones\"]\n",
    "opt_utilized_feas = opt_dict_feas[\"opt_utilized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten opt_time\n",
    "opt_time_feas_mean = np.mean(opt_time_feas)\n",
    "print(\"Average optimization time: \", np.mean(opt_time_feas))\n",
    "# flatten opt_time\n",
    "opt_val_feas_mean = np.mean(opt_val_feas)\n",
    "print(\"Average optimization value: \", np.mean(opt_val_feas))\n",
    "print(\"Number of feasible model\", len(opt_time_feas))\n",
    "print(\"Number of ones: \", opt_ones_feas)\n",
    "print(\"Number of variable utilized \", opt_utilized_feas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate time sped up by and optimality difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_time_feas_arr = np.array(opt_time_feas)\n",
    "opt_val_feas_arr = np.array(opt_val_feas)\n",
    "opt_time_arr = np.array(opt_time)\n",
    "opt_val_arr = np.array(opt_val)\n",
    "\n",
    "inf_id = np.where(opt_time_feas_arr == 0.0)\n",
    "\n",
    "opt_time_feas_arr[inf_id] = opt_time_arr[inf_id]\n",
    "opt_val_feas_arr[inf_id] = opt_val_arr[inf_id]\n",
    "\n",
    "spd_up = 1-(np.array(opt_time_feas_arr)/np.array(opt_time_arr))\n",
    "opt_loss = ((np.array(opt_val_feas_arr) - np.array(opt_val_arr))/np.array(opt_val_arr))\n",
    "\n",
    "feasible_model_feas = len(opt_time_feas) / len(model_test) * 100\n",
    "# ones_utilized_feas = np.array(opt_ones_feas) / np.array(opt_ones) *100\n",
    "# prediction_utilized_feas = np.array(opt_utilized_feas) / len(index_test[0]) *100\n",
    "\n",
    "print(f\"Time sped up: {np.mean(spd_up)*100} %\")\n",
    "print(f\"Optimality Loss: {np.mean(opt_loss)*100} %\")\n",
    "print(f\"Feasible model: {feasible_model_feas} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
