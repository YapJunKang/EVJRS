{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, Dropout, Conv2d, MaxPool2d\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import gurobipy as gb\n",
    "from gurobipy import GRB\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# set CUDA_VISIBLE_DEVICES=0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dir = os.path.join(os.getcwd(), \"dataGeneration/preprocessed_data_test\")\n",
    "\n",
    "X_test = np.load(os.path.join(train_test_dir, \"X_test.npy\"))\n",
    "y_test = np.load(os.path.join(train_test_dir, \"y_test.npy\"))\n",
    "index_test = np.load(os.path.join(train_test_dir, \"indices_test.npy\")).astype(\"int64\")\n",
    "\n",
    "solTime_test = np.load(os.path.join(train_test_dir, \"solTime_test.npy\"))\n",
    "objVal_test = np.load(os.path.join(train_test_dir, \"objVal_test.npy\"))\n",
    "schedule_test = np.load(os.path.join(train_test_dir, \"schedule_test.npy\")).astype(\"int32\")\n",
    "model_test = np.load(os.path.join(train_test_dir, \"model_test.npy\")).astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 5, 169, 48)\n",
      "float64\n",
      "(200, 5, 767300)\n",
      "float64\n",
      "(200, 5, 767300)\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "X_test = np.transpose(X_test, (0,1,3,2))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_test.dtype)\n",
    "print(y_test.shape)\n",
    "print(y_test.dtype)\n",
    "print(index_test.shape)\n",
    "print(index_test.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169 48 767300\n"
     ]
    }
   ],
   "source": [
    "in_channels = X_test.shape[2]\n",
    "col = X_test.shape[3]\n",
    "\n",
    "out_channels = y_test.shape[-1]\n",
    "nbScen = X_test.shape[1]\n",
    "\n",
    "print(in_channels, col, out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.hidden_ch = 64\n",
    "        self.dp = 0.1\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, self.hidden_ch, 11, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dp),\n",
    "            nn.MaxPool1d(5, stride=1, padding=0),\n",
    "\n",
    "            nn.Conv1d(self.hidden_ch, self.hidden_ch*2, 7, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dp),\n",
    "            nn.MaxPool1d(5, stride=1, padding=0),\n",
    "\n",
    "            nn.Conv1d(self.hidden_ch*2, self.hidden_ch, 3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dp),\n",
    "            nn.MaxPool1d(5, stride=1, padding=0),\n",
    "        )\n",
    "        \n",
    "        n_channels = self.feature_extractor(torch.zeros(1, in_channels, col)).size(-1)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.MaxPool1d(n_channels), # GAP\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.hidden_ch, self.hidden_ch*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dp),\n",
    "            nn.Linear(self.hidden_ch*2, self.hidden_ch*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dp),\n",
    "            nn.Linear(self.hidden_ch*2, out_channels),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        out = self.classifier(features)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'batch_size' : 8, # Num samples to average over for gradient updates\n",
    "        'EPOCHS' : 500, # Num times to iterate over the entire dataset\n",
    "        'LEARNING_RATE' : 5e-4, # Learning rate for the optimizer\n",
    "        'WEIGHT_DECAY' : 1e-4, # Weight decay parameter for the Adam optimizer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class coordinationDataset(TensorDataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(coordinationDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "        \n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        y_tensor = torch.round(torch.tensor(y, dtype=torch.float32))\n",
    "\n",
    "        return X_tensor, y_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 169, 48)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = coordinationDataset(X_test, y_test)\n",
    "\n",
    "print(test_dataset.X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork()\n",
    "\n",
    "batch_size = config['batch_size']\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=config[\"LEARNING_RATE\"])\n",
    "total_steps = len(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetric_loss(predict, target, gamma_neg=0.3, gamma_pos=0, clip=0.0, eps=1e-8, disable_torch_grad_focal_loss=True):\n",
    "\n",
    "    \"\"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: input logits\n",
    "    y: targets (multi-label binarized vector)\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculating Probabilities\n",
    "    x_sigmoid = predict\n",
    "    xs_pos = x_sigmoid\n",
    "    xs_neg = 1 - x_sigmoid\n",
    "\n",
    "    # Asymmetric Clipping\n",
    "    if clip is not None and clip > 0:\n",
    "        xs_neg = (xs_neg + clip).clamp(max=1)\n",
    "\n",
    "    # Basic CE calculation\n",
    "    los_pos = target * torch.log(xs_pos.clamp(min=eps))\n",
    "    los_neg = (1 - target) * torch.log(xs_neg.clamp(min=eps))\n",
    "    loss = los_pos + los_neg\n",
    "\n",
    "    # Asymmetric Focusing\n",
    "    if gamma_neg > 0 or gamma_pos > 0:\n",
    "        if disable_torch_grad_focal_loss:\n",
    "            torch.set_grad_enabled(False)\n",
    "        pt0 = xs_pos * target\n",
    "        pt1 = xs_neg * (1 - target)  # pt = p if t > 0 else 1-p\n",
    "        pt = pt0 + pt1\n",
    "        one_sided_gamma = gamma_pos * target + gamma_neg * (1 - target)\n",
    "        one_sided_w = torch.pow(1 - pt, one_sided_gamma)\n",
    "        if disable_torch_grad_focal_loss:\n",
    "            torch.set_grad_enabled(True)\n",
    "        loss *= one_sided_w\n",
    "\n",
    "    return -loss.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jkang\\AppData\\Local\\Temp\\ipykernel_14048\\2140383097.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(os.path.join(os.getcwd(), f\"ML_Model/CNN_1D_coordination_{interval}.pth\")))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "interval = 20\n",
    "\n",
    "net = NeuralNetwork()\n",
    "net.load_state_dict(torch.load(os.path.join(os.getcwd(), f\"ML_Model/CNN_1D_coordination_{interval}.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv1d(169, 64, kernel_size=(11,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): MaxPool1d(kernel_size=5, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv1d(64, 128, kernel_size=(7,), stride=(1,))\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.1, inplace=False)\n",
       "    (7): MaxPool1d(kernel_size=5, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv1d(128, 64, kernel_size=(3,), stride=(1,))\n",
       "    (9): ReLU()\n",
       "    (10): Dropout(p=0.1, inplace=False)\n",
       "    (11): MaxPool1d(kernel_size=5, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): MaxPool1d(kernel_size=18, stride=18, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.1, inplace=False)\n",
       "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.1, inplace=False)\n",
       "    (8): Linear(in_features=128, out_features=767300, bias=True)\n",
       "    (9): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test number of feasible solutions\n",
    "# test the model on the test set\n",
    "net.eval()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing of bit accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average one bit accuracy 0.60444015\n",
      "Average zero bit accuracy 0.9985646\n",
      "Average bit accuracy 0.9962103\n",
      "Loss: 0.01090041869902052\n",
      "0.70020235 0.99563277\n"
     ]
    }
   ],
   "source": [
    "thres = 0.5\n",
    "\n",
    "one_accuracy = []\n",
    "zero_accuracy = []\n",
    "bit_accuracy = []\n",
    "running_loss = 0\n",
    "mean_one = []\n",
    "mean_zero = []\n",
    "\n",
    "for j, data in enumerate(test_loader):\n",
    "    \n",
    "    net.eval()\n",
    "    inputs_all, labels_all = data\n",
    "\n",
    "    # do a for loop to perform perdiction for each scenario\n",
    "    output_append = torch.tensor([], device=device)\n",
    "    gt_append = torch.tensor([], device=device)\n",
    "\n",
    "    for x in range(nbScen):\n",
    "        \n",
    "        inputs, labels = inputs_all[:,x,:,:].to(device), labels_all[:,x,:,].to(device)       \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        output_append = torch.concat((output_append, outputs),dim=1)\n",
    "        gt_append = torch.concat((gt_append, labels),dim=1)\n",
    "\n",
    "    output_append = output_append.reshape(-1,)\n",
    "    gt_append = gt_append.reshape(-1,)\n",
    "\n",
    "    loss_fn = nn.BCELoss()\n",
    "    loss = loss_fn(output_append, gt_append)\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    # start testing\n",
    "    outputs_percent = output_append\n",
    "    output_append = torch.where(output_append >= thres, torch.ceil(output_append), torch.floor(output_append)).reshape(-1,)\n",
    "    # outputs = torch.round(outputs)\n",
    "\n",
    "    one_labels = torch.where(gt_append == 1)\n",
    "    zero_labels = torch.where(gt_append == 0)\n",
    "    \n",
    "    one_outputs = output_append[one_labels]\n",
    "    zero_outputs = output_append[zero_labels]\n",
    "\n",
    "    one_acc = 1 - torch.sum(torch.abs(1 - one_outputs)) / one_outputs.shape[0] # 1 minus percentage of error\n",
    "    zero_acc = 1 - torch.sum(torch.abs(0 - zero_outputs)) / zero_outputs.shape[0]\n",
    "    bit_acc = 1 - torch.sum(torch.abs(output_append - gt_append)) / gt_append.shape[0]\n",
    "\n",
    "    one_accuracy.append(one_acc.cpu().detach().numpy())\n",
    "    zero_accuracy.append(zero_acc.cpu().detach().numpy())\n",
    "    bit_accuracy.append(bit_acc.cpu().detach().numpy())\n",
    "\n",
    "    # mean acc\n",
    "    id_1 = torch.where(output_append == 1)\n",
    "    id_0 = torch.where(output_append == 0)\n",
    "\n",
    "    p_1 = outputs_percent[id_1]\n",
    "    p_0 = outputs_percent[id_0]\n",
    "\n",
    "\n",
    "    y_1 = gt_append[id_1]\n",
    "    y_0 = gt_append[id_0]\n",
    "\n",
    "    y_1_1 = torch.where(y_1 == 1)\n",
    "    y_1_0 = torch.where(y_1 == 0)\n",
    "    y_0_1 = torch.where(y_0 == 1)\n",
    "    y_0_0 = torch.where(y_0 == 0)\n",
    "\n",
    "    avg_1 = torch.mean(torch.cat((p_1[y_1_1], torch.ones(y_1_0[0].shape[0]).to(device) - p_1[y_1_0])))\n",
    "    avg_0 = torch.mean(torch.cat((p_0[y_0_1], torch.ones(y_0_0[0].shape[0]).to(device) - p_0[y_0_0])))\n",
    "\n",
    "    # avg_1 = torch.mean(torch.cat((p_1[y_1_1],  p_1[y_1_0])))\n",
    "    # avg_0 = torch.mean(torch.cat((p_0[y_0_1], p_0[y_0_0])))\n",
    "\n",
    "    # avg_1 = torch.mean(p_1[y_1_1])\n",
    "    # avg_0 = torch.mean(p_0[y_0_1])\n",
    "\n",
    "    # avg_1 = torch.mean(p_1[y_1_0])\n",
    "    # avg_0 = torch.mean(p_0[y_0_1])\n",
    "\n",
    "    mean_one.append(avg_1.cpu().detach().numpy())\n",
    "    mean_zero.append(avg_0.cpu().detach().numpy())\n",
    "\n",
    "print(\"Average one bit accuracy\", np.mean(one_accuracy))\n",
    "print(\"Average zero bit accuracy\", np.mean(zero_accuracy))\n",
    "print(\"Average bit accuracy\", np.mean(bit_accuracy))\n",
    "print('Loss:', running_loss / len(test_loader))\n",
    "print(np.mean(mean_one), np.mean(mean_zero))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for baseline solving speed (speed cap at 300 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2592862\n",
      "Academic license - for non-commercial use only - expires 2025-11-29\n",
      "Optimization time for model  0 :  5242.073000192642\n",
      "Optimization Value for model  0 :  1284184.37081262\n",
      "Optimization time for model  1 :  27.53500008583069\n",
      "Optimization Value for model  1 :  1305235.433362448\n",
      "Optimization time for model  2 :  7200.074999809265\n",
      "Optimization Value for model  2 :  1337602.9584201737\n",
      "Optimization time for model  3 :  369.0110001564026\n",
      "Optimization Value for model  3 :  1371761.5977044152\n",
      "Optimization time for model  4 :  7200.516000032425\n",
      "Optimization Value for model  4 :  1448389.8199385172\n",
      "Optimization time for model  5 :  7200.322000026703\n",
      "Optimization Value for model  5 :  1386413.5596961677\n",
      "Optimization time for model  6 :  7200.254999876022\n",
      "Optimization Value for model  6 :  1420292.038576436\n",
      "Optimization time for model  7 :  6846.6849999427795\n",
      "Optimization Value for model  7 :  1431480.6251091622\n",
      "Optimization time for model  8 :  711.8229999542236\n",
      "Optimization Value for model  8 :  1382464.719913374\n",
      "Optimization time for model  9 :  7200.350000143051\n",
      "Optimization Value for model  9 :  1444246.0909442636\n",
      "Optimization time for model  10 :  7200.3840000629425\n",
      "Optimization Value for model  10 :  1410089.3364395988\n",
      "Optimization time for model  11 :  7200.3550000190735\n",
      "Optimization Value for model  11 :  1413870.9057232537\n",
      "Optimization time for model  12 :  7202.659999847412\n",
      "Optimization Value for model  12 :  1376600.3699997463\n",
      "Optimization time for model  13 :  6719.740000009537\n",
      "Optimization Value for model  13 :  1271836.6904120606\n",
      "Optimization time for model  14 :  7200.255000114441\n",
      "Optimization Value for model  14 :  1389373.6616867513\n",
      "Optimization time for model  15 :  7200.283999919891\n",
      "Optimization Value for model  15 :  1462702.8345118903\n",
      "Optimization time for model  16 :  7200.532999992371\n",
      "Optimization Value for model  16 :  1323806.0847645446\n",
      "Optimization time for model  17 :  7200.517000198364\n",
      "Optimization Value for model  17 :  1385015.7084162552\n",
      "Optimization time for model  18 :  390.9630000591278\n",
      "Optimization Value for model  18 :  1483639.173371818\n",
      "Optimization time for model  19 :  7200.97100019455\n",
      "Optimization Value for model  19 :  1390874.2478284454\n",
      "Optimization time for model  20 :  1809.7269999980927\n",
      "Optimization Value for model  20 :  1456435.4547697015\n",
      "Optimization time for model  21 :  7200.521000146866\n",
      "Optimization Value for model  21 :  1366815.693796295\n",
      "Optimization time for model  22 :  436.02999997138977\n",
      "Optimization Value for model  22 :  1468220.1054882812\n",
      "Optimization time for model  23 :  7204.359999895096\n",
      "Optimization Value for model  23 :  1467208.8654294752\n",
      "Optimization time for model  24 :  88.40100002288818\n",
      "Optimization Value for model  24 :  1295314.2922224826\n",
      "Optimization time for model  25 :  7200.5599999427795\n",
      "Optimization Value for model  25 :  1351882.392444762\n",
      "Optimization time for model  26 :  7200.383000135422\n",
      "Optimization Value for model  26 :  1397058.7289132134\n",
      "Optimization time for model  27 :  394.68800020217896\n",
      "Optimization Value for model  27 :  1466819.2876622854\n",
      "Optimization time for model  28 :  7203.420000076294\n",
      "Optimization Value for model  28 :  1481617.1894578547\n",
      "Optimization time for model  29 :  7200.521999835968\n",
      "Optimization Value for model  29 :  1308276.7676614649\n",
      "Optimization time for model  30 :  2104.5970001220703\n",
      "Optimization Value for model  30 :  1441780.988251398\n",
      "Optimization time for model  31 :  7200.305999994278\n",
      "Optimization Value for model  31 :  1414086.913072715\n",
      "Optimization time for model  32 :  7200.6520001888275\n",
      "Optimization Value for model  32 :  1417736.6871394631\n",
      "Optimization time for model  33 :  7200.560000181198\n",
      "Optimization Value for model  33 :  1446385.369112124\n",
      "Optimization time for model  34 :  7200.575000047684\n",
      "Optimization Value for model  34 :  1411848.0654600621\n",
      "Optimization time for model  35 :  7200.06299996376\n",
      "Optimization Value for model  35 :  1319736.5442319964\n",
      "Optimization time for model  36 :  7200.393000125885\n",
      "Optimization Value for model  36 :  1416024.3758968876\n",
      "Optimization time for model  37 :  7200.361000061035\n",
      "Optimization Value for model  37 :  1311084.8238822487\n",
      "Optimization time for model  38 :  7204.960999965668\n",
      "Optimization Value for model  38 :  1437917.9834793287\n",
      "Optimization time for model  39 :  7200.34500002861\n",
      "Optimization Value for model  39 :  1439106.995035322\n",
      "Optimization time for model  40 :  7200.368000030518\n",
      "Optimization Value for model  40 :  1352859.70913064\n",
      "Optimization time for model  41 :  7200.848999977112\n",
      "Optimization Value for model  41 :  1389130.7521171384\n",
      "Optimization time for model  42 :  7202.480999946594\n",
      "Optimization Value for model  42 :  1332318.814661775\n",
      "Optimization time for model  43 :  7202.561000108719\n",
      "Optimization Value for model  43 :  1434986.525495915\n",
      "Optimization time for model  44 :  7200.624000072479\n",
      "Optimization Value for model  44 :  1454875.195776381\n",
      "Optimization time for model  45 :  7200.608999967575\n",
      "Optimization Value for model  45 :  1414619.878560508\n",
      "Optimization time for model  46 :  95.03600001335144\n",
      "Optimization Value for model  46 :  1302841.6530156047\n",
      "Optimization time for model  47 :  7200.430999994278\n",
      "Optimization Value for model  47 :  1386758.1867015956\n",
      "Optimization time for model  48 :  7202.548000097275\n",
      "Optimization Value for model  48 :  1459390.144669258\n",
      "Optimization time for model  49 :  7200.930999994278\n",
      "Optimization Value for model  49 :  1461606.2734777106\n",
      "Optimization time for model  50 :  7200.673000097275\n",
      "Optimization Value for model  50 :  1486095.9114553947\n",
      "Optimization time for model  51 :  7201.970999956131\n",
      "Optimization Value for model  51 :  1461937.476187227\n",
      "Optimization time for model  52 :  7200.756999969482\n",
      "Optimization Value for model  52 :  1458849.3674829486\n",
      "Optimization time for model  53 :  7200.90700006485\n",
      "Optimization Value for model  53 :  1498531.3013132748\n",
      "Optimization time for model  54 :  7200.447999954224\n",
      "Optimization Value for model  54 :  1457949.4839899957\n",
      "Optimization time for model  55 :  7200.919999837875\n",
      "Optimization Value for model  55 :  1461725.4182075358\n",
      "Optimization time for model  56 :  7200.901999950409\n",
      "Optimization Value for model  56 :  1443482.4095252233\n",
      "Optimization time for model  57 :  7200.036999940872\n",
      "Optimization Value for model  57 :  1306864.302410369\n",
      "Optimization time for model  58 :  7200.672000169754\n",
      "Optimization Value for model  58 :  1423286.1214542428\n",
      "Optimization time for model  59 :  7201.4329998493195\n",
      "Optimization Value for model  59 :  1520914.2607277932\n",
      "Optimization time for model  60 :  7200.9690001010895\n",
      "Optimization Value for model  60 :  1524208.074381053\n",
      "Optimization time for model  61 :  7201.496999979019\n",
      "Optimization Value for model  61 :  1493157.3868037732\n",
      "Optimization time for model  62 :  7200.925999879837\n",
      "Optimization Value for model  62 :  1451460.8565289066\n",
      "Optimization time for model  63 :  7207.081000089645\n",
      "Optimization Value for model  63 :  1416609.3556580094\n",
      "Optimization time for model  64 :  7200.888000011444\n",
      "Optimization Value for model  64 :  1565228.2562720515\n",
      "Optimization time for model  65 :  7200.967000007629\n",
      "Optimization Value for model  65 :  1432163.6761361558\n",
      "Optimization time for model  66 :  7200.8949999809265\n",
      "Optimization Value for model  66 :  1439790.5179524056\n",
      "Optimization time for model  67 :  7200.986000061035\n",
      "Optimization Value for model  67 :  1430108.163877888\n",
      "Optimization time for model  68 :  104.26400017738342\n",
      "Optimization Value for model  68 :  1334028.3465917734\n",
      "Optimization time for model  69 :  7203.02999997139\n",
      "Optimization Value for model  69 :  1452059.5725211424\n",
      "Optimization time for model  70 :  7200.5090000629425\n",
      "Optimization Value for model  70 :  1414363.678836893\n",
      "Optimization time for model  71 :  7200.944000005722\n",
      "Optimization Value for model  71 :  1495526.1987802214\n",
      "Optimization time for model  72 :  7201.0199999809265\n",
      "Optimization Value for model  72 :  1522829.0923893421\n",
      "Optimization time for model  73 :  7206.0650000572205\n",
      "Optimization Value for model  73 :  1489945.329472201\n",
      "Optimization time for model  74 :  7200.983999967575\n",
      "Optimization Value for model  74 :  1417055.2530910275\n",
      "Optimization time for model  75 :  7200.544000148773\n",
      "Optimization Value for model  75 :  1498988.6764230127\n",
      "Optimization time for model  76 :  2481.382999897003\n",
      "Optimization Value for model  76 :  1386652.9814189347\n",
      "Optimization time for model  77 :  7200.967000007629\n",
      "Optimization Value for model  77 :  1470052.9962338656\n",
      "Optimization time for model  78 :  7200.417000055313\n",
      "Optimization Value for model  78 :  1433868.7060589842\n",
      "Optimization time for model  79 :  7200.091000080109\n",
      "Optimization Value for model  79 :  1319121.4925827647\n",
      "Optimization time for model  80 :  7207.218000173569\n",
      "Optimization Value for model  80 :  1437329.9218427977\n",
      "Optimization time for model  81 :  7201.0759999752045\n",
      "Optimization Value for model  81 :  1448716.9927519266\n",
      "Optimization time for model  82 :  7201.09700012207\n",
      "Optimization Value for model  82 :  1412615.0955565681\n",
      "Optimization time for model  83 :  7201.900000095367\n",
      "Optimization Value for model  83 :  1472716.9772264182\n",
      "Optimization time for model  84 :  7205.014999866486\n",
      "Optimization Value for model  84 :  1445280.2419475731\n",
      "Optimization time for model  85 :  7201.210000038147\n",
      "Optimization Value for model  85 :  1528288.9121122083\n",
      "Optimization time for model  86 :  7201.105999946594\n",
      "Optimization Value for model  86 :  1519343.0260935565\n",
      "Optimization time for model  87 :  7200.460999965668\n",
      "Optimization Value for model  87 :  1452971.1238924416\n",
      "Optimization time for model  88 :  7200.380000114441\n",
      "Optimization Value for model  88 :  1485031.553008271\n",
      "Optimization time for model  89 :  7200.355999946594\n",
      "Optimization Value for model  89 :  1458316.1815152038\n",
      "Optimization time for model  90 :  135.8109998703003\n",
      "Optimization Value for model  90 :  1326829.4938878757\n",
      "Optimization time for model  91 :  7200.362999916077\n",
      "Optimization Value for model  91 :  1519102.851770872\n",
      "Optimization time for model  92 :  7200.382999897003\n",
      "Optimization Value for model  92 :  1450720.3978035287\n",
      "Optimization time for model  93 :  7200.505999803543\n",
      "Optimization Value for model  93 :  1563621.268509477\n",
      "Optimization time for model  94 :  7200.517999887466\n",
      "Optimization Value for model  94 :  1460959.041239283\n",
      "Optimization time for model  95 :  7200.476999998093\n",
      "Optimization Value for model  95 :  1417269.9549452232\n",
      "Optimization time for model  96 :  7200.4059998989105\n",
      "Optimization Value for model  96 :  1481618.7415543806\n",
      "Optimization time for model  97 :  7201.602999925613\n",
      "Optimization Value for model  97 :  1483817.9394453655\n",
      "Optimization time for model  98 :  7200.430000066757\n",
      "Optimization Value for model  98 :  1512731.7160512526\n",
      "Optimization time for model  99 :  1501.1480000019073\n",
      "Optimization Value for model  99 :  1526816.534412148\n",
      "Optimization time for model  100 :  7200.4359998703\n",
      "Optimization Value for model  100 :  1552005.952783701\n",
      "Optimization time for model  101 :  7200.048000097275\n",
      "Optimization Value for model  101 :  1246308.653606955\n",
      "Optimization time for model  102 :  785.1339998245239\n",
      "Optimization Value for model  102 :  1569932.472102723\n",
      "Optimization time for model  103 :  7200.391999959946\n",
      "Optimization Value for model  103 :  1511228.8416045182\n",
      "Optimization time for model  104 :  7200.592000007629\n",
      "Optimization Value for model  104 :  1557170.0596847911\n",
      "Optimization time for model  105 :  7201.234999895096\n",
      "Optimization Value for model  105 :  1485403.6587297176\n",
      "Optimization time for model  106 :  7200.518000125885\n",
      "Optimization Value for model  106 :  1491839.5928625332\n",
      "Optimization time for model  107 :  7200.427999973297\n",
      "Optimization Value for model  107 :  1434608.403830844\n",
      "Optimization time for model  108 :  7200.487999916077\n",
      "Optimization Value for model  108 :  1560216.8111260347\n",
      "Optimization time for model  109 :  7200.397000074387\n",
      "Optimization Value for model  109 :  1499510.9944308123\n",
      "Optimization time for model  110 :  7200.544000148773\n",
      "Optimization Value for model  110 :  1511919.403517674\n",
      "Optimization time for model  111 :  7200.537000179291\n",
      "Optimization Value for model  111 :  1495099.5777601197\n",
      "Optimization time for model  112 :  5240.012000083923\n",
      "Optimization Value for model  112 :  1309152.87920635\n",
      "Optimization time for model  113 :  7200.0599999427795\n",
      "Optimization Value for model  113 :  1359106.8932791052\n",
      "Optimization time for model  114 :  155.5059998035431\n",
      "Optimization Value for model  114 :  1207438.017571572\n",
      "Optimization time for model  115 :  685.7569999694824\n",
      "Optimization Value for model  115 :  1399898.7341229976\n",
      "Optimization time for model  116 :  7200.082000017166\n",
      "Optimization Value for model  116 :  1255362.3339976156\n",
      "Optimization time for model  117 :  7200.06299996376\n",
      "Optimization Value for model  117 :  1326933.1453559902\n",
      "Optimization time for model  118 :  7200.118999958038\n",
      "Optimization Value for model  118 :  1351095.2164940038\n",
      "Optimization time for model  119 :  3652.100000143051\n",
      "Optimization Value for model  119 :  1277317.7154430135\n",
      "Optimization time for model  120 :  3328.338000059128\n",
      "Optimization Value for model  120 :  1302619.049143521\n",
      "Optimization time for model  121 :  7200.096999883652\n",
      "Optimization Value for model  121 :  1372886.2699669963\n",
      "Optimization time for model  122 :  7200.093999862671\n",
      "Optimization Value for model  122 :  1321902.7481484017\n",
      "Optimization time for model  123 :  3933.952000141144\n",
      "Optimization Value for model  123 :  1261689.3474300052\n",
      "Optimization time for model  124 :  214.42300009727478\n",
      "Optimization Value for model  124 :  1374552.3514173052\n",
      "Optimization time for model  125 :  210.46000003814697\n",
      "Optimization Value for model  125 :  1374871.5264752123\n",
      "Optimization time for model  126 :  7200.052999973297\n",
      "Optimization Value for model  126 :  1346317.0967380756\n",
      "Optimization time for model  127 :  88.73799991607666\n",
      "Optimization Value for model  127 :  1346796.0095456294\n",
      "Optimization time for model  128 :  146.31199979782104\n",
      "Optimization Value for model  128 :  1417729.672995502\n",
      "Optimization time for model  129 :  7200.091000080109\n",
      "Optimization Value for model  129 :  1344180.6045095439\n",
      "Optimization time for model  130 :  198.51600003242493\n",
      "Optimization Value for model  130 :  1338580.7772195076\n",
      "Optimization time for model  131 :  7200.120000123978\n",
      "Optimization Value for model  131 :  1342330.205571421\n",
      "Optimization time for model  132 :  97.2829999923706\n",
      "Optimization Value for model  132 :  1391642.42752654\n",
      "Optimization time for model  133 :  7200.115000009537\n",
      "Optimization Value for model  133 :  1417965.2171207573\n",
      "Optimization time for model  134 :  7200.025000095367\n",
      "Optimization Value for model  134 :  1319081.4309883728\n",
      "Optimization time for model  135 :  7200.111999988556\n",
      "Optimization Value for model  135 :  1413622.8733634907\n",
      "Optimization time for model  136 :  7200.076999902725\n",
      "Optimization Value for model  136 :  1402378.5977456295\n",
      "Optimization time for model  137 :  7200.059000015259\n",
      "Optimization Value for model  137 :  1370052.3271286837\n",
      "Optimization time for model  138 :  7200.055000066757\n",
      "Optimization Value for model  138 :  1329711.8056005372\n",
      "Optimization time for model  139 :  7200.072000026703\n",
      "Optimization Value for model  139 :  1374519.0899351037\n",
      "Optimization time for model  140 :  7200.040999889374\n",
      "Optimization Value for model  140 :  1333549.230800136\n",
      "Optimization time for model  141 :  7200.15499997139\n",
      "Optimization Value for model  141 :  1390541.706672641\n",
      "Optimization time for model  142 :  224.76500010490417\n",
      "Optimization Value for model  142 :  1385468.8631922698\n",
      "Optimization time for model  143 :  7200.066999912262\n",
      "Optimization Value for model  143 :  1331781.4305119263\n",
      "Optimization time for model  144 :  7200.107000112534\n",
      "Optimization Value for model  144 :  1354802.681458117\n",
      "Optimization time for model  145 :  7200.074000120163\n",
      "Optimization Value for model  145 :  1218599.1441017499\n",
      "Optimization time for model  146 :  7200.063999891281\n",
      "Optimization Value for model  146 :  1365919.6392445487\n",
      "Optimization time for model  147 :  7200.135999917984\n",
      "Optimization Value for model  147 :  1423328.6759397727\n",
      "Optimization time for model  148 :  7200.174999952316\n",
      "Optimization Value for model  148 :  1315496.7041236726\n",
      "Optimization time for model  149 :  7200.09500002861\n",
      "Optimization Value for model  149 :  1402837.7494220117\n",
      "Optimization time for model  150 :  7200.098999977112\n",
      "Optimization Value for model  150 :  1395928.7685670394\n",
      "Optimization time for model  151 :  7200.120000123978\n",
      "Optimization Value for model  151 :  1345237.0602959194\n",
      "Optimization time for model  152 :  7200.083999872208\n",
      "Optimization Value for model  152 :  1404182.3030847306\n",
      "Optimization time for model  153 :  7200.082000017166\n",
      "Optimization Value for model  153 :  1346916.0115483436\n",
      "Optimization time for model  154 :  7200.226999998093\n",
      "Optimization Value for model  154 :  1461073.688849589\n",
      "Optimization time for model  155 :  7200.1340000629425\n",
      "Optimization Value for model  155 :  1397797.6586646074\n",
      "Optimization time for model  156 :  64.2590000629425\n",
      "Optimization Value for model  156 :  1268348.9979252762\n",
      "Optimization time for model  157 :  7200.1829998493195\n",
      "Optimization Value for model  157 :  1437226.8852231877\n",
      "Optimization time for model  158 :  7200.103000164032\n",
      "Optimization Value for model  158 :  1453282.0043881375\n",
      "Optimization time for model  159 :  7200.15700006485\n",
      "Optimization Value for model  159 :  1414466.9825186075\n",
      "Optimization time for model  160 :  7200.389000177383\n",
      "Optimization Value for model  160 :  1404205.2702908164\n",
      "Optimization time for model  161 :  7200.098999977112\n",
      "Optimization Value for model  161 :  1403571.280442727\n",
      "Optimization time for model  162 :  538.0950000286102\n",
      "Optimization Value for model  162 :  1372436.7522161566\n",
      "Optimization time for model  163 :  7200.1159999370575\n",
      "Optimization Value for model  163 :  1423817.6468382766\n",
      "Optimization time for model  164 :  7200.1050000190735\n",
      "Optimization Value for model  164 :  1428960.9163907333\n",
      "Optimization time for model  165 :  7208.638999938965\n",
      "Optimization Value for model  165 :  1463309.3164344588\n",
      "Optimization time for model  166 :  7200.431999921799\n",
      "Optimization Value for model  166 :  1461679.7667810335\n",
      "Optimization time for model  167 :  45.31599998474121\n",
      "Optimization Value for model  167 :  1302703.9340560555\n",
      "Optimization time for model  168 :  7200.084000110626\n",
      "Optimization Value for model  168 :  1380657.692304\n",
      "Optimization time for model  169 :  7203.491000175476\n",
      "Optimization Value for model  169 :  1466755.6913642788\n",
      "Optimization time for model  170 :  7200.207999944687\n",
      "Optimization Value for model  170 :  1447638.9565247952\n",
      "Optimization time for model  171 :  7200.746999979019\n",
      "Optimization Value for model  171 :  1376837.5686301948\n",
      "Optimization time for model  172 :  2713.516000032425\n",
      "Optimization Value for model  172 :  1422471.5402447493\n",
      "Optimization time for model  173 :  7200.483000040054\n",
      "Optimization Value for model  173 :  1426997.6988058838\n",
      "Optimization time for model  174 :  7201.177999973297\n",
      "Optimization Value for model  174 :  1494212.3986338475\n",
      "Optimization time for model  175 :  7200.100999832153\n",
      "Optimization Value for model  175 :  1394368.7927057939\n",
      "Optimization time for model  176 :  7200.223999977112\n",
      "Optimization Value for model  176 :  1435065.176093235\n",
      "Optimization time for model  177 :  7200.121000051498\n",
      "Optimization Value for model  177 :  1445910.8921724304\n",
      "Optimization time for model  178 :  48.70700001716614\n",
      "Optimization Value for model  178 :  1304102.6913978967\n",
      "Optimization time for model  179 :  7200.117000102997\n",
      "Optimization Value for model  179 :  1419098.5316554285\n",
      "Optimization time for model  180 :  7200.499000072479\n",
      "Optimization Value for model  180 :  1512768.33167486\n",
      "Optimization time for model  181 :  7200.496000051498\n",
      "Optimization Value for model  181 :  1490322.9037029184\n",
      "Optimization time for model  182 :  7200.2809998989105\n",
      "Optimization Value for model  182 :  1438577.4276038865\n",
      "Optimization time for model  183 :  7200.878000020981\n",
      "Optimization Value for model  183 :  1434879.5792044024\n",
      "Optimization time for model  184 :  7200.095999956131\n",
      "Optimization Value for model  184 :  1511445.5776550653\n",
      "Optimization time for model  185 :  7200.759999990463\n",
      "Optimization Value for model  185 :  1474477.7264760633\n",
      "Optimization time for model  186 :  7200.170000076294\n",
      "Optimization Value for model  186 :  1476397.9562011014\n",
      "Optimization time for model  187 :  7200.266000032425\n",
      "Optimization Value for model  187 :  1563040.089194715\n",
      "Optimization time for model  188 :  7200.816999912262\n",
      "Optimization Value for model  188 :  1480888.0144668566\n",
      "Optimization time for model  189 :  3999.4420001506805\n",
      "Optimization Value for model  189 :  1338010.6270377312\n",
      "Optimization time for model  190 :  7200.879999876022\n",
      "Optimization Value for model  190 :  1421137.8612496667\n",
      "Optimization time for model  191 :  7200.272000074387\n",
      "Optimization Value for model  191 :  1459003.932192345\n",
      "Optimization time for model  192 :  7200.2809998989105\n",
      "Optimization Value for model  192 :  1441947.684969512\n",
      "Optimization time for model  193 :  7200.089999914169\n",
      "Optimization Value for model  193 :  1426773.8929579002\n",
      "Optimization time for model  194 :  763.8269999027252\n",
      "Optimization Value for model  194 :  1469583.4584650837\n",
      "Optimization time for model  195 :  784.4160001277924\n",
      "Optimization Value for model  195 :  1575913.308785779\n",
      "Optimization time for model  196 :  824.5139999389648\n",
      "Optimization Value for model  196 :  1506993.7265738803\n",
      "Optimization time for model  197 :  7200.076999902725\n",
      "Optimization Value for model  197 :  1444158.043266479\n",
      "Optimization time for model  198 :  7201.517999887466\n",
      "Optimization Value for model  198 :  1516945.1784653002\n",
      "Optimization time for model  199 :  7200.221999883652\n",
      "Optimization Value for model  199 :  1411236.1178695974\n"
     ]
    }
   ],
   "source": [
    "gurobi_env = gb.Env()\n",
    "gurobi_env.setParam(\"OutputFlag\", 0)\n",
    "    \n",
    "# loop through all test models and calculate average optimization time\n",
    "opt_time = []\n",
    "opt_val = []\n",
    "opt_ones = []\n",
    "for i, _ in enumerate(model_test):\n",
    "    \n",
    "    runtime = solTime_test[i]\n",
    "    obj = objVal_test[i]\n",
    "    \n",
    "    print(\"Optimization time for model \", i, \": \", runtime)\n",
    "    print(\"Optimization Value for model \", i, \": \", obj)\n",
    "    \n",
    "    opt_time.append(runtime)\n",
    "    opt_val.append(obj)\n",
    "\n",
    "    nbEV = np.max(schedule_test[i][:,0]) + 1\n",
    "    binary_vars = y_test[i]\n",
    "\n",
    "    opt_ones.append(np.count_nonzero(np.round(binary_vars)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dict = {\n",
    "    \"opt_time\": opt_time,\n",
    "    \"opt_val\": opt_val,\n",
    "    \"opt_ones\": opt_ones\n",
    "}\n",
    "\n",
    "result_path = os.path.join(os.getcwd(), f\"Results\")\n",
    "with open(os.path.join(result_path, \"opt_test.pkl\"), 'wb') as f:\n",
    "    pickle.dump(opt_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = os.path.join(os.getcwd(), f\"Results\")\n",
    "with open(os.path.join(result_path, \"opt_test.pkl\"), 'rb') as f:\n",
    "    opt_dict = pickle.load(f)\n",
    "\n",
    "opt_time = opt_dict[\"opt_time\"]\n",
    "opt_val = opt_dict[\"opt_val\"]\n",
    "opt_ones = opt_dict[\"opt_ones\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average optimization time:  6051.671590007543\n",
      "Average optimization value:  1417083.2321979306\n",
      "Number of ones:  [7075, 7083, 9452, 17724, 21136, 20725, 20698, 21026, 20936, 21316, 21568, 21369, 21062, 9917, 22093, 22024, 21865, 22692, 22014, 22719, 23052, 23004, 19466, 23062, 8411, 22857, 22686, 23551, 23757, 23228, 24372, 23805, 24027, 24055, 24579, 10533, 24229, 24619, 24237, 24739, 21331, 25203, 25183, 25276, 22003, 25754, 9270, 26133, 26264, 25953, 26508, 26277, 26489, 26328, 26707, 26893, 27018, 10930, 27387, 27998, 27433, 27479, 27895, 27810, 23799, 27888, 28288, 28515, 9561, 28253, 28171, 28615, 29371, 29291, 29738, 29768, 29622, 29260, 29790, 9628, 29498, 30115, 26000, 30414, 29910, 30692, 30081, 31103, 30936, 31355, 9884, 31334, 31273, 31707, 31586, 31425, 31151, 31633, 32121, 32774, 33011, 10579, 27926, 33020, 33325, 33495, 32696, 33600, 33467, 33412, 33769, 28898, 7405, 12284, 11565, 12724, 13046, 13223, 13903, 14147, 14320, 14064, 14637, 7543, 14359, 14388, 15675, 15935, 13646, 16556, 16232, 16427, 17309, 17200, 7880, 17695, 18227, 17839, 18356, 18682, 19066, 19211, 16789, 19934, 20433, 8185, 21009, 20780, 21176, 21413, 21571, 21958, 21880, 22575, 23431, 22601, 7003, 23247, 23340, 23661, 24215, 24457, 24031, 25133, 25010, 21557, 25336, 8707, 25844, 22486, 22569, 26787, 27180, 27537, 27657, 24012, 23991, 27964, 9024, 27979, 28096, 29307, 29002, 29587, 29938, 30264, 30162, 30510, 30963, 9282, 31214, 31744, 31321, 32043, 27899, 27922, 28228, 33404, 33505, 33551]\n"
     ]
    }
   ],
   "source": [
    "# flatten opt_time\n",
    "print(\"Average optimization time: \", np.mean(opt_time))\n",
    "opt_time_baseline = np.mean(opt_time)\n",
    "# flatten opt_time\n",
    "print(\"Average optimization value: \", np.mean(opt_val))\n",
    "opt_val_baseline = np.mean(opt_val)\n",
    "print(\"Number of ones: \", opt_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the optimization time for each instance in the test set if we use $\\color{lightblue}\\text{equality constraint}$ to find optimal solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start testing equality constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in paramaeters\n",
    "data_dir = os.path.join(os.getcwd(), 'systemData')\n",
    "EV_routes = pd.read_csv(os.path.join(data_dir, 'EV_routes.csv')).to_numpy()\n",
    "bus_params = pd.read_csv(os.path.join(data_dir, 'bus_params.csv')).to_numpy()\n",
    "# EV_schedules = pd.read_csv(os.path.join(data_dir, 'EV_schedules.csv')).to_numpy().astype(\"int32\")\n",
    "\n",
    "nbTime, nbBus, nbRoute = 48, bus_params.shape[0], EV_routes.shape[0]\n",
    "traffic = np.zeros(nbTime-1)\n",
    "traffic[14:20] = 1      # from 7-10am \n",
    "traffic[32:40] = 1      # from 4-8pm\n",
    "\n",
    "charging_station = np.squeeze(pd.read_csv(os.path.join(data_dir, 'cs_params_variable.csv')).to_numpy())\n",
    "non_charging_station = np.array([i for i in range(nbBus) if i not in charging_station])\n",
    "nbCS = len(charging_station)\n",
    "\n",
    "normal_nodes =  list(charging_station) + list(range(101,108))\n",
    "virtual_nodes = list(range(201,205))\n",
    "congest_nodes = list(range(301,324))\n",
    "\n",
    "always_arc, normal_arc, congest_arc = [], [], []\n",
    "\n",
    "for r in range(nbRoute):\n",
    "    if (EV_routes[r,1] in (normal_nodes+virtual_nodes)) and (EV_routes[r,2] in (normal_nodes+virtual_nodes)) and (EV_routes[r,1] != EV_routes[r,2]):\n",
    "        normal_arc.append(r)\n",
    "    elif (EV_routes[r,1] in (normal_nodes+virtual_nodes)) and (EV_routes[r,2] in congest_nodes):\n",
    "        congest_arc.append(r)\n",
    "    else:\n",
    "        always_arc.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_EV= 100\n",
    "var_per_EV = (nbRoute*(nbTime-1) + nbCS*nbTime*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2592862\n",
      "Academic license - for non-commercial use only - expires 2025-11-29\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  2 :  1337603.8683535054\n",
      "Optimization value for model  2 :  8.665046215057373\n",
      "Optimization time for model  3 :  1371759.0463044154\n",
      "Optimization value for model  3 :  18.16520357131958\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  8 :  1382461.781913377\n",
      "Optimization value for model  8 :  18.02458643913269\n",
      "infeasible\n",
      "Optimization time for model  10 :  1410088.9767065076\n",
      "Optimization value for model  10 :  17.957112073898315\n",
      "Optimization time for model  11 :  1413940.279989934\n",
      "Optimization value for model  11 :  18.354421138763428\n",
      "infeasible\n",
      "Optimization time for model  13 :  1271838.1610787255\n",
      "Optimization value for model  13 :  8.04884672164917\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  18 :  1483637.9799718051\n",
      "Optimization value for model  18 :  18.39132261276245\n",
      "infeasible\n",
      "Optimization time for model  20 :  1456435.6567696987\n",
      "Optimization value for model  20 :  17.253833055496216\n",
      "Optimization time for model  21 :  1366884.6829963126\n",
      "Optimization value for model  21 :  20.05125141143799\n",
      "Optimization time for model  22 :  1468218.8159549483\n",
      "Optimization value for model  22 :  20.700499057769775\n",
      "Optimization time for model  23 :  1467107.7714294663\n",
      "Optimization value for model  23 :  17.364176750183105\n",
      "Optimization time for model  24 :  1295281.3568891522\n",
      "Optimization value for model  24 :  8.122872829437256\n",
      "Optimization time for model  25 :  1351879.6868447626\n",
      "Optimization value for model  25 :  17.16369366645813\n",
      "Optimization time for model  26 :  1397065.5068175124\n",
      "Optimization value for model  26 :  19.08218741416931\n",
      "Optimization time for model  27 :  1466849.588395619\n",
      "Optimization value for model  27 :  21.461143493652344\n",
      "infeasible\n",
      "Optimization time for model  29 :  1308344.3785955\n",
      "Optimization value for model  29 :  17.040417671203613\n",
      "infeasible\n",
      "Optimization time for model  31 :  1414222.2620060463\n",
      "Optimization value for model  31 :  18.180710554122925\n",
      "infeasible\n",
      "Optimization time for model  33 :  1446483.4421121243\n",
      "Optimization value for model  33 :  19.07276749610901\n",
      "Optimization time for model  34 :  1411848.1617267258\n",
      "Optimization value for model  34 :  20.073296070098877\n",
      "Optimization time for model  35 :  1319736.8580319206\n",
      "Optimization value for model  35 :  10.523924589157104\n",
      "Optimization time for model  36 :  1416159.107097122\n",
      "Optimization value for model  36 :  20.333492040634155\n",
      "Optimization time for model  37 :  1311118.2698155825\n",
      "Optimization value for model  37 :  19.739356756210327\n",
      "Optimization time for model  38 :  1437918.3315462628\n",
      "Optimization value for model  38 :  20.89912486076355\n",
      "Optimization time for model  39 :  1439175.1075686584\n",
      "Optimization value for model  39 :  18.908234357833862\n",
      "Optimization time for model  40 :  1352860.057197307\n",
      "Optimization value for model  40 :  21.081539630889893\n",
      "Optimization time for model  41 :  1389130.8230505607\n",
      "Optimization value for model  41 :  20.642394304275513\n",
      "infeasible\n",
      "Optimization time for model  43 :  1434985.5219625814\n",
      "Optimization value for model  43 :  19.864850521087646\n",
      "Optimization time for model  44 :  1454943.1769763816\n",
      "Optimization value for model  44 :  24.680406093597412\n",
      "infeasible\n",
      "Optimization time for model  46 :  1302840.4781489305\n",
      "Optimization value for model  46 :  8.839908838272095\n",
      "infeasible\n",
      "Optimization time for model  48 :  1459390.3828025896\n",
      "Optimization value for model  48 :  23.8294677734375\n",
      "Optimization time for model  49 :  1461606.511277863\n",
      "Optimization value for model  49 :  24.39661741256714\n",
      "Optimization time for model  50 :  1486095.1413220637\n",
      "Optimization value for model  50 :  24.29513144493103\n",
      "Optimization time for model  51 :  1462072.858453826\n",
      "Optimization value for model  51 :  20.271974802017212\n",
      "Optimization time for model  52 :  1458849.6704829445\n",
      "Optimization value for model  52 :  21.184497356414795\n",
      "Optimization time for model  53 :  1498541.1913791748\n",
      "Optimization value for model  53 :  24.996747732162476\n",
      "infeasible\n",
      "Optimization time for model  55 :  1461793.3744742225\n",
      "Optimization value for model  55 :  22.100642442703247\n",
      "Optimization time for model  56 :  1443482.62139189\n",
      "Optimization value for model  56 :  22.9122793674469\n",
      "Optimization time for model  57 :  1306864.3780770353\n",
      "Optimization value for model  57 :  10.209736585617065\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  64 :  1565228.432938718\n",
      "Optimization value for model  64 :  25.38098955154419\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  68 :  1334029.532258443\n",
      "Optimization value for model  68 :  9.430599689483643\n",
      "Optimization time for model  69 :  1452127.7614539112\n",
      "Optimization value for model  69 :  22.127872943878174\n",
      "infeasible\n",
      "Optimization time for model  71 :  1495660.428392654\n",
      "Optimization value for model  71 :  23.7429621219635\n",
      "infeasible\n",
      "Optimization time for model  73 :  1490081.1216055334\n",
      "Optimization value for model  73 :  21.898523092269897\n",
      "Optimization time for model  74 :  1417186.9544243645\n",
      "Optimization value for model  74 :  20.861834049224854\n",
      "Optimization time for model  75 :  1498989.0752896797\n",
      "Optimization value for model  75 :  23.122016429901123\n",
      "infeasible\n",
      "Optimization time for model  77 :  1470053.2185005324\n",
      "Optimization value for model  77 :  25.30829429626465\n",
      "Optimization time for model  78 :  1433868.9739256527\n",
      "Optimization value for model  78 :  25.259884119033813\n",
      "Optimization time for model  79 :  1319189.164382768\n",
      "Optimization value for model  79 :  10.682236433029175\n",
      "Optimization time for model  80 :  1437127.5131095652\n",
      "Optimization value for model  80 :  22.385302782058716\n",
      "Optimization time for model  81 :  1448849.4088190717\n",
      "Optimization value for model  81 :  24.870411157608032\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  85 :  1528355.917381256\n",
      "Optimization value for model  85 :  24.763858556747437\n",
      "Optimization time for model  86 :  1519409.139626226\n",
      "Optimization value for model  86 :  25.473848819732666\n",
      "infeasible\n",
      "Optimization time for model  88 :  1485029.9668105412\n",
      "Optimization value for model  88 :  26.01993680000305\n",
      "Optimization time for model  89 :  1458246.8611152072\n",
      "Optimization value for model  89 :  23.592466115951538\n",
      "infeasible\n",
      "Optimization time for model  91 :  1519105.2058385382\n",
      "Optimization value for model  91 :  27.265862941741943\n",
      "Optimization time for model  92 :  1450684.6548035305\n",
      "Optimization value for model  92 :  26.478378772735596\n",
      "infeasible\n",
      "Optimization time for model  94 :  1460924.1969059445\n",
      "Optimization value for model  94 :  25.033456087112427\n",
      "Optimization time for model  95 :  1417336.7708118898\n",
      "Optimization value for model  95 :  27.54238271713257\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  100 :  1552005.2380503684\n",
      "Optimization value for model  100 :  29.352221727371216\n",
      "Optimization time for model  101 :  1246309.001673622\n",
      "Optimization value for model  101 :  10.822814226150513\n",
      "Optimization time for model  102 :  1569998.45876939\n",
      "Optimization value for model  102 :  28.575193881988525\n",
      "Optimization time for model  103 :  1511256.72711104\n",
      "Optimization value for model  103 :  25.014119386672974\n",
      "Optimization time for model  104 :  1556928.4123231946\n",
      "Optimization value for model  104 :  25.826684713363647\n",
      "infeasible\n",
      "Optimization time for model  106 :  1491839.592862832\n",
      "Optimization value for model  106 :  25.793623685836792\n",
      "infeasible\n",
      "Optimization time for model  108 :  1560182.8626593703\n",
      "Optimization value for model  108 :  25.633193492889404\n",
      "Optimization time for model  109 :  1499441.9384311337\n",
      "Optimization value for model  109 :  29.798945426940918\n",
      "infeasible\n",
      "Optimization time for model  111 :  1495098.853226758\n",
      "Optimization value for model  111 :  27.549229621887207\n",
      "infeasible\n",
      "Optimization time for model  113 :  1359106.8932791066\n",
      "Optimization value for model  113 :  10.041213512420654\n",
      "Optimization time for model  114 :  1207436.9564382322\n",
      "Optimization value for model  114 :  10.397956371307373\n",
      "Optimization time for model  115 :  1399899.0169229966\n",
      "Optimization value for model  115 :  10.124132633209229\n",
      "infeasible\n",
      "Optimization time for model  117 :  1326933.2162893284\n",
      "Optimization value for model  117 :  10.443803310394287\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  126 :  1346283.478538079\n",
      "Optimization value for model  126 :  12.255695343017578\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  130 :  1338583.3346861256\n",
      "Optimization value for model  130 :  14.390304327011108\n",
      "Optimization time for model  131 :  1342330.3018378746\n",
      "Optimization value for model  131 :  12.631389141082764\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  135 :  1413690.135096825\n",
      "Optimization value for model  135 :  13.354964256286621\n",
      "infeasible\n",
      "Optimization time for model  137 :  1370053.4481956535\n",
      "Optimization value for model  137 :  14.37574291229248\n",
      "infeasible\n",
      "Optimization time for model  139 :  1374519.7365354793\n",
      "Optimization value for model  139 :  15.783007860183716\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  142 :  1385603.29345894\n",
      "Optimization value for model  142 :  17.78384017944336\n",
      "Optimization time for model  143 :  1331779.986844961\n",
      "Optimization value for model  143 :  14.527167558670044\n",
      "Optimization time for model  144 :  1354769.1392581167\n",
      "Optimization value for model  144 :  14.296592473983765\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  150 :  1395997.7115670429\n",
      "Optimization value for model  150 :  15.549774646759033\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  153 :  1346934.6641082184\n",
      "Optimization value for model  153 :  17.677457809448242\n",
      "Optimization time for model  154 :  1461207.2952497092\n",
      "Optimization value for model  154 :  17.233749389648438\n",
      "infeasible\n",
      "Optimization time for model  156 :  1268349.6743918979\n",
      "Optimization value for model  156 :  6.782552242279053\n",
      "Optimization time for model  157 :  1437359.919089852\n",
      "Optimization value for model  157 :  16.908223152160645\n",
      "infeasible\n",
      "Optimization time for model  159 :  1414599.7478519427\n",
      "Optimization value for model  159 :  18.88410258293152\n",
      "Optimization time for model  160 :  1404337.3212241482\n",
      "Optimization value for model  160 :  20.615209102630615\n",
      "Optimization time for model  161 :  1403571.4067760606\n",
      "Optimization value for model  161 :  18.221214294433594\n",
      "infeasible\n",
      "Optimization time for model  163 :  1423817.3627716117\n",
      "Optimization value for model  163 :  19.5723078250885\n",
      "Optimization time for model  164 :  1429058.6293240678\n",
      "Optimization value for model  164 :  18.824382066726685\n",
      "Optimization time for model  165 :  1463309.417767793\n",
      "Optimization value for model  165 :  20.97256064414978\n",
      "Optimization time for model  166 :  1461680.276981035\n",
      "Optimization value for model  166 :  22.26660418510437\n",
      "Optimization time for model  167 :  1302771.4931893556\n",
      "Optimization value for model  167 :  6.916558265686035\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  170 :  1447774.8205247954\n",
      "Optimization value for model  170 :  21.91828727722168\n",
      "Optimization time for model  171 :  1376770.6403620986\n",
      "Optimization value for model  171 :  21.967671155929565\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  178 :  1304103.0394645622\n",
      "Optimization value for model  178 :  7.122710466384888\n",
      "infeasible\n",
      "Optimization time for model  180 :  1512768.4782748607\n",
      "Optimization value for model  180 :  24.917252779006958\n",
      "infeasible\n",
      "Optimization time for model  182 :  1438710.7421372198\n",
      "Optimization value for model  182 :  24.550572156906128\n",
      "Optimization time for model  183 :  1434879.6298710974\n",
      "Optimization value for model  183 :  23.485540866851807\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "infeasible\n",
      "Optimization time for model  188 :  1480888.110731266\n",
      "Optimization value for model  188 :  27.966763496398926\n",
      "infeasible\n",
      "Optimization time for model  190 :  1421139.9771829972\n",
      "Optimization value for model  190 :  27.065801858901978\n",
      "infeasible\n",
      "Optimization time for model  192 :  1441948.5587028458\n",
      "Optimization value for model  192 :  27.865002155303955\n",
      "infeasible\n",
      "Optimization time for model  194 :  1469649.536531751\n",
      "Optimization value for model  194 :  39.999666690826416\n",
      "Optimization time for model  195 :  1575977.1649858572\n",
      "Optimization value for model  195 :  28.57430863380432\n",
      "Optimization time for model  196 :  1506991.5444405472\n",
      "Optimization value for model  196 :  30.42489194869995\n",
      "infeasible\n",
      "Optimization time for model  198 :  1516945.2794653082\n",
      "Optimization value for model  198 :  28.700044631958008\n",
      "Optimization time for model  199 :  1411233.4518695958\n",
      "Optimization value for model  199 :  25.129133462905884\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "gurobi_env = gb.Env()\n",
    "gurobi_env.setParam(\"OutputFlag\", 0)\n",
    "\n",
    "# loop through all test models and calculate average optimization time\n",
    "opt_time_thres = []\n",
    "opt_val_thres = []\n",
    "opt_ones_thres = []\n",
    "opt_utilized_thres = []\n",
    "for i, x in enumerate(model_test):\n",
    "    \n",
    "    path = os.path.join(os.getcwd(), \"dataGeneration/model_test\")\n",
    "\n",
    "    model = gb.read(os.path.join(path, f\"coordination_{x}.mps\"), env=gurobi_env)\n",
    "    model.setParam(\"OutputFlag\", 0)\n",
    "    model.setParam(\"TimeLimit\", 120*60)\n",
    "\n",
    "    ################# timing the first code block #####################\n",
    "    start = time.time()\n",
    "\n",
    "    # deep learning prediciton\n",
    "    output_append = torch.tensor([], device=device)\n",
    "    gt_append = torch.tensor([], device=device)\n",
    "\n",
    "    for s in range(nbScen):\n",
    "        inputs = torch.tensor(np.expand_dims(test_dataset.X[i][s], axis=0), dtype=torch.float32) \n",
    "        inputs = inputs.to(device)    \n",
    "        outputs = net(inputs) \n",
    "\n",
    "        # extract correct amount of binary before concat\n",
    "        nbEV = np.max(schedule_test[i][:,0]) + 1\n",
    "        outs = outputs[:,0:var_per_EV*nbEV]\n",
    "        gts = torch.tensor(y_test[i,s,0:var_per_EV*nbEV], device=device).reshape(1,-1)\n",
    "\n",
    "        output_append = torch.concat((output_append, outs),dim=1)\n",
    "        gt_append = torch.concat((gt_append, gts),dim=1)\n",
    "\n",
    "    output_append = output_append.reshape(-1,)\n",
    "    gt_append = gt_append.reshape(-1,)\n",
    "\n",
    "    ################## end #########################\n",
    "\n",
    "    y_pred_binary =  (output_append).reshape(-1,).cpu().detach().numpy()\n",
    "    # y_pred_binary = gt_append.reshape(-1,).cpu().detach().numpy()\n",
    "\n",
    "    modelVars = model.getVars()\n",
    "\n",
    "    # bin_id = []\n",
    "    # ###### Build the index for the variables ######\n",
    "    # for sc in range(nbScen):\n",
    "    #     for k in range(nbEV):\n",
    "    #         # for each EV get each attribute and order it based on EV number\n",
    "    #         for r in range(nbRoute):\n",
    "    #             for t in range(nbTime-1):\n",
    "    #                 var = model.getVarByName(f\"EVArcStatus[{sc},{k},{r},{t}]\")\n",
    "\n",
    "    #                 bin_id.append(var.index)\n",
    "\n",
    "    #     for k in range(nbEV):\n",
    "    #         for c in range(nbCS):\n",
    "    #             for t in range(nbTime):\n",
    "    #                 var = model.getVarByName(f\"EVChargeStatus[{sc},{k},{c},{t}]\")\n",
    "\n",
    "    #                 bin_id.append(var.index)\n",
    "                    \n",
    "    #     for k in range(nbEV):\n",
    "    #         for c in range(nbCS):\n",
    "    #             for t in range(nbTime):\n",
    "    #                 var = model.getVarByName(f\"EVDischargeStatus[{sc},{k},{c},{t}]\")\n",
    "\n",
    "    #                 bin_id.append(var.index)\n",
    "    ################## end #########################\n",
    "    \n",
    "    # get correct amount of index\n",
    "    bin_id = index_test[i][0:var_per_EV*nbEV*nbScen].reshape(-1,)\n",
    "\n",
    "    one_threshold = (np.mean(mean_one))\n",
    "    zero_threshold = (1-np.mean(mean_zero))\n",
    "\n",
    "    # use equality constraint from here on\n",
    "    for j in range(len(y_pred_binary)):\n",
    "        if (y_pred_binary[j] >= one_threshold or y_pred_binary[j] <= zero_threshold):\n",
    "        # if (y_pred_binary[j] >= 0):\n",
    "            modelVars[bin_id[j]].setAttr(\"LB\", round(y_pred_binary[j]))\n",
    "            modelVars[bin_id[j]].setAttr(\"UB\", round(y_pred_binary[j]))\n",
    "            \n",
    "    end = time.time()\n",
    "    runtime1 = end - start\n",
    "\n",
    "    opt_ones_thres.append(np.count_nonzero(y_pred_binary >= one_threshold))\n",
    "    opt_utilized_thres.append(np.count_nonzero(y_pred_binary >= one_threshold)+  np.count_nonzero(y_pred_binary <= zero_threshold))\n",
    "\n",
    "    ################# timing the second code block #####################\n",
    "    start = time.time()\n",
    "\n",
    "    model.optimize()\n",
    "\n",
    "    end = time.time()\n",
    "    runtime2 = end - start\n",
    "    runtime = runtime1 + runtime2\n",
    "    ################## end #########################\n",
    "    \n",
    "    try:\n",
    "        print(\"Optimization time for model \", i, \": \", model.ObjVal)\n",
    "        print(\"Optimization value for model \", i, \": \", runtime)\n",
    "        opt_time_thres.append(runtime)\n",
    "        opt_val_thres.append(model.ObjVal)\n",
    "    except:\n",
    "        print(\"infeasible\")\n",
    "\n",
    "    \n",
    "    model.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dict_thres = {\n",
    "    \"opt_time\": opt_time_thres,\n",
    "    \"opt_val\": opt_val_thres,\n",
    "    \"opt_ones\": opt_ones_thres,\n",
    "    \"opt_utilized\": opt_utilized_thres\n",
    "}\n",
    "\n",
    "result_path = os.path.join(os.getcwd(), f\"Results\")\n",
    "with open(os.path.join(result_path, f\"CNN_1D_{interval}_test_opt_thres.pkl\"), 'wb') as f:\n",
    "    pickle.dump(opt_dict_thres, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"CNN_1D_{interval}_test_opt_thres.pkl\"), 'rb') as f:\n",
    "    opt_dict_thres = pickle.load(f)\n",
    "\n",
    "opt_time_thres = opt_dict_thres[\"opt_time\"]\n",
    "opt_val_thres = opt_dict_thres[\"opt_val\"]\n",
    "opt_ones_thres = opt_dict_thres[\"opt_ones\"]\n",
    "opt_utilized_thres = opt_dict_thres[\"opt_utilized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average optimization time:  20.867736981131813\n",
      "Average optimization value:  1424707.1059614248\n",
      "Number of feasible model 165\n",
      "Number of ones:  [2982, 3166, 4449, 9494, 11586, 9380, 11748, 9035, 9768, 9529, 10079, 9251, 11135, 4589, 10719, 11116, 9292, 9270, 9710, 13013, 11518, 9966, 10123, 12090, 3729, 11628, 11705, 10758, 13329, 10545, 12101, 10948, 11596, 12284, 12200, 5123, 11195, 10777, 11542, 11008, 11719, 12464, 12941, 12590, 12394, 11015, 5273, 15012, 12392, 12362, 11268, 11833, 11940, 12020, 13274, 14535, 12293, 5278, 13610, 15823, 15287, 13482, 13021, 15671, 13316, 15400, 15373, 15986, 5227, 14580, 11875, 15504, 16217, 13637, 16386, 15823, 13958, 14867, 16368, 6361, 16058, 16328, 12139, 15585, 13809, 14726, 14675, 15478, 17243, 17316, 5740, 13367, 17370, 15095, 17755, 17499, 15263, 18210, 17357, 14353, 13853, 5184, 14319, 15928, 16084, 15903, 14095, 15767, 17473, 18994, 18454, 13792, 3074, 6266, 6184, 5709, 6829, 7860, 5358, 6546, 6578, 8007, 5230, 2664, 6519, 6460, 8951, 7625, 7308, 6602, 7711, 8411, 8127, 8453, 3756, 10156, 7701, 8657, 8453, 8732, 8516, 9995, 8786, 8752, 10907, 3917, 7870, 11250, 9350, 12057, 12297, 10566, 12526, 11657, 13205, 13218, 3543, 11378, 13357, 12721, 12639, 11324, 11599, 12613, 13757, 11840, 12053, 3620, 14553, 12707, 11994, 13538, 13098, 15571, 11356, 13204, 11627, 11744, 3844, 13056, 12662, 11835, 13815, 13394, 12003, 15622, 15928, 15313, 12911, 4313, 13917, 17339, 14139, 14710, 14438, 14228, 14364, 14970, 15104, 17234]\n",
      "Number of variable utilized  [757512, 761396, 1030546, 2244427, 2241991, 2269628, 2247798, 2267947, 2282987, 2265579, 2343451, 2304140, 2305672, 1051274, 2383500, 2349422, 2343056, 2423768, 2419731, 2433284, 2445239, 2446270, 2459879, 2485025, 1056310, 2486082, 2489252, 2529445, 2537634, 2570801, 2596961, 2645061, 2619191, 2599497, 2636234, 1153382, 2640547, 2688387, 2683932, 2719840, 2686493, 2712404, 2761820, 2755982, 2798573, 2795837, 1131164, 2800519, 2819669, 2821015, 2826876, 2907006, 2907449, 2862342, 2905506, 2901778, 2889028, 1164944, 2975142, 2976845, 2974971, 2979750, 3012773, 3013896, 3015958, 3051158, 3050196, 3054675, 1203590, 3141626, 3087690, 3083316, 3156195, 3205420, 3169088, 3256781, 3199375, 3205979, 3232477, 1209811, 3228815, 3230180, 3271894, 3260579, 3265335, 3384747, 3383856, 3334043, 3408900, 3436847, 1242897, 3361219, 3378930, 3401438, 3420185, 3425639, 3446967, 3466515, 3510345, 3514313, 3506718, 1320790, 3499097, 3522494, 3545057, 3532964, 3594289, 3592115, 3657435, 3638954, 3691545, 3616508, 793088, 1316607, 1360192, 1378701, 1389789, 1435661, 1482271, 1506097, 1542197, 1541656, 1577191, 803786, 1615560, 1614442, 1694674, 1724873, 1716346, 1755284, 1797565, 1794161, 1867340, 1866591, 833148, 1914119, 1939887, 1942314, 2013005, 2054537, 2087201, 2084367, 2130910, 2127583, 2176620, 871952, 2238609, 2247116, 2273722, 2281791, 2316908, 2386225, 2360898, 2421767, 2462258, 2468171, 867163, 2481067, 2539037, 2532546, 2601621, 2611842, 2645280, 2719314, 2683761, 2763715, 2792897, 941927, 2789088, 2827548, 2907909, 2860458, 2904748, 2978822, 2973515, 3064633, 3015077, 3050875, 979587, 3132779, 3075343, 3156306, 3243413, 3194114, 3229952, 3261207, 3266458, 3348466, 3328514, 1001762, 3367168, 3474492, 3398755, 3430066, 3505904, 3499857, 3534649, 3589959, 3584981, 3606669]\n"
     ]
    }
   ],
   "source": [
    "# flatten opt_time\n",
    "opt_time_thres_mean = np.mean(opt_time_thres)\n",
    "print(\"Average optimization time: \", opt_time_thres_mean)\n",
    "# flatten opt_time\n",
    "opt_val_thres_mean = np.mean(opt_val_thres)\n",
    "print(\"Average optimization value: \", np.mean(opt_val_thres))\n",
    "print(\"Number of feasible model\", len(opt_time_thres))\n",
    "print(\"Number of ones: \", opt_ones_thres)\n",
    "print(\"Number of variable utilized \", opt_utilized_thres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing equality constraint with feasibility check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read in paramaeters\n",
    "# data_dir = os.path.join(os.getcwd(), 'systemData')\n",
    "# EV_routes = pd.read_csv(os.path.join(data_dir, 'EV_routes.csv')).to_numpy()\n",
    "# bus_params = pd.read_csv(os.path.join(data_dir, 'bus_params.csv')).to_numpy()\n",
    "# # EV_schedules = pd.read_csv(os.path.join(data_dir, 'EV_schedules.csv')).to_numpy().astype(\"int32\")\n",
    "\n",
    "# nbScen, nbTime, nbEV, nbBus, nbRoute = 5, 48, 5, bus_params.shape[0], EV_routes.shape[0]\n",
    "# traffic = np.zeros(nbTime-1)\n",
    "# traffic[14:20] = 1      # from 7-10am \n",
    "# traffic[32:40] = 1      # from 4-8pm\n",
    "\n",
    "# charging_station = [4, 8, 14, 20, 23, 28]\n",
    "# non_charging_station = np.array([i for i in range(nbBus) if i not in charging_station])\n",
    "# nbCS = len(charging_station)\n",
    "\n",
    "# normal_nodes =  charging_station + list(range(101,108))\n",
    "# virtual_nodes = list(range(201,205))\n",
    "# congest_nodes = list(range(301,324))\n",
    "\n",
    "# always_arc, normal_arc, congest_arc = [], [], []\n",
    "\n",
    "# for r in range(nbRoute):\n",
    "#     if (EV_routes[r,1] in (normal_nodes+virtual_nodes)) and (EV_routes[r,2] in (normal_nodes+virtual_nodes)) and (EV_routes[r,1] != EV_routes[r,2]):\n",
    "#         normal_arc.append(r)\n",
    "#     elif (EV_routes[r,1] in (normal_nodes+virtual_nodes)) and (EV_routes[r,2] in congest_nodes):\n",
    "#         congest_arc.append(r)\n",
    "#     else:\n",
    "#         always_arc.append(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution_check(y_pred_binary, model, index_test, EV_schedules):\n",
    "\n",
    "    variables = model.getVars()\n",
    "    nbEV = np.max(EV_schedules[:,0]) + 1\n",
    "\n",
    "    EV_schedules = EV_schedules[0:nbEV*4,:]\n",
    "\n",
    "    # ========================================= initialise parameters ===================================================\n",
    "\n",
    "    EVArcStatus = np.zeros((nbScen, nbEV, nbRoute, nbTime-1))\n",
    "    EVArcStatusIndex = np.zeros((nbScen, nbEV, nbRoute, nbTime-1))\n",
    "    EVChargeStatus = np.zeros((nbScen, nbEV, nbCS, nbTime))\n",
    "    EVChargeStatusIndex = np.zeros((nbScen, nbEV, nbCS, nbTime))\n",
    "    EVDischargeStatus = np.zeros((nbScen, nbEV, nbCS, nbTime))\n",
    "    EVDischargeStatusIndex = np.zeros((nbScen, nbEV, nbCS, nbTime))\n",
    "\n",
    "    id_count = 0\n",
    "    for sc in range(nbScen):\n",
    "        for k in range(nbEV):\n",
    "            # for each EV get each attribute and order it based on EV number\n",
    "            for r in range(nbRoute):\n",
    "                for t in range(nbTime-1):\n",
    "                    EVArcStatus[sc,k,r,t] = y_pred_binary[id_count]\n",
    "                    EVArcStatusIndex[sc,k,r,t] = y_pred_binary[id_count]\n",
    "                    id_count = id_count + 1\n",
    "\n",
    "            for c in range(nbCS):\n",
    "                for t in range(nbTime):\n",
    "                    EVChargeStatus[sc,k,c,t] = y_pred_binary[id_count]\n",
    "                    EVChargeStatusIndex[sc,k,c,t] = y_pred_binary[id_count]\n",
    "                    id_count = id_count + 1\n",
    "\n",
    "            for c in range(nbCS):\n",
    "                for t in range(nbTime):\n",
    "                    EVDischargeStatus[sc,k,c,t] = y_pred_binary[id_count]\n",
    "                    EVDischargeStatusIndex[sc,k,c,t] = y_pred_binary[id_count]\n",
    "                    id_count = id_count + 1\n",
    "\n",
    "    # corrected_y = y_pred_binary\n",
    "\n",
    "    # ========================================= checking Arc constestts ===================================================\n",
    "    # set disable arc to 0 and check activated arc\n",
    "    for sc in range(nbScen):\n",
    "        for s in range(nbTime-1):\n",
    "            \n",
    "            activate_arc = (always_arc + congest_arc) if traffic[s] else (always_arc + normal_arc)\n",
    "            disable_arc = normal_arc if traffic[s] else congest_arc\n",
    "            \n",
    "            EVArcStatus[sc,:,np.array(disable_arc),s] = 0\n",
    "\n",
    "        # check for EVArcStatus sum == 1\n",
    "        MoveStatus = np.sum(np.round(np.clip(EVArcStatus[sc], 0, None)), axis=1)\n",
    "        # print(MoveStatus)\n",
    "        for i in range(MoveStatus.shape[0]):\n",
    "            for j in range(MoveStatus.shape[1]):\n",
    "\n",
    "                activate_arc = (always_arc + congest_arc) if traffic[j] else (always_arc + normal_arc)\n",
    "\n",
    "                if MoveStatus[i,j] == 0:\n",
    "                    EVArcStatus[sc,i,activate_arc,j] = -1\n",
    "                elif MoveStatus[i,j] > 1:\n",
    "                    EVArcStatus[sc,i,:,j] = -1\n",
    "                    # max = np.argmax(EVArcStatus[i,:,j])\n",
    "                    # EVArcStatus[i,:,j] = 0\n",
    "                        # EVArcStatus[i,max,j] = 1\n",
    "\n",
    "        MoveStatus = np.sum(np.round(np.clip(EVArcStatus[sc], 0, None)), axis=1)\n",
    "        # print(MoveStatus)\n",
    "\n",
    "        # check EVArc Continuity\n",
    "        for k in range(nbEV):\n",
    "            for s in range(nbTime-2):\n",
    "                from_arc = np.max(np.round(EVArcStatus[sc,k,:,s]))\n",
    "                to_arc = np.max(np.round(EVArcStatus[sc,k,:,s+1]))\n",
    "\n",
    "                if from_arc == 1 and to_arc == 1:\n",
    "                    from_node = np.argmax(np.round(EVArcStatus[sc,k,:,s]))\n",
    "                    to_node = np.argmax(np.round(EVArcStatus[sc,k,:,s+1]))\n",
    "\n",
    "                    activate_arc = (always_arc + congest_arc) if traffic[s] else (always_arc + normal_arc)\n",
    "                    \n",
    "                    if EV_routes[from_node, 2] != EV_routes[to_node, 1]:\n",
    "                        EVArcStatus[sc,k,:,s] = -1\n",
    "                        EVArcStatus[sc,k,:,s+1] = -1\n",
    "                else:\n",
    "                    EVArcStatus[sc,k,:,s] = -1\n",
    "                    EVArcStatus[sc,k,:,s+1] = -1\n",
    "\n",
    "        # check schedule\n",
    "        nbSchedule = EV_schedules.shape[0]\n",
    "        for k in range(nbSchedule):\n",
    "            schedule = EV_schedules[k]  # [EV, destination, time]\n",
    "\n",
    "            route_index = (EV_routes[:,1]==schedule[1]).nonzero()[0] if schedule[2] == 0 else (EV_routes[:,2]==schedule[1]).nonzero()[0]\n",
    "            time = 0 if schedule[2] == 0 else schedule[2]-1\n",
    "\n",
    "            activate_arc = (always_arc + congest_arc) if traffic[time] else (always_arc + normal_arc)\n",
    "            disable_arc = normal_arc if traffic[time] else congest_arc\n",
    "\n",
    "            MoveStatus = np.sum(np.round(np.clip(EVArcStatus[sc,schedule[0], route_index, time], 0, None)))\n",
    "            if MoveStatus == 0:\n",
    "                EVArcStatus[sc,schedule[0],activate_arc,time] = 0\n",
    "                EVArcStatus[sc,schedule[0],route_index,time] = -1\n",
    "            elif MoveStatus > 1:\n",
    "                EVArcStatus[sc,schedule[0],activate_arc,time] = -1\n",
    "                # max = np.argmax(EVArcStatus[schedule[0],route_index,time])\n",
    "                # EVArcStatus[schedule[0],:,time] = 0\n",
    "                # EVArcStatus[schedule[0],max,time] = 1\n",
    "\n",
    "    # ========================================= checking charge constestts ===================================================\n",
    "        stationary_index = np.array((EV_routes[:,1] == EV_routes[:,2]).nonzero()[0])\n",
    "        charging_index = np.array([i for i, e in enumerate(EV_routes[:,1]) if e in charging_station])\n",
    "        charge_index = [i for i, e in enumerate(stationary_index) if e in charging_index]\n",
    "\n",
    "        for k in range(nbEV):\n",
    "            for i, ii in enumerate(stationary_index[charge_index]):\n",
    "                for s in range(nbTime-1):\n",
    "                    if not ((np.round(np.clip(EVChargeStatus[sc,k,i,s+1], 0, None)) + np.round(np.clip(EVDischargeStatus[sc,k,i,s+1], 0, None))) <= np.round(np.clip(EVArcStatus[sc,k,ii,s], 0, None))):\n",
    "                        EVChargeStatus[sc,k,i,s+1] = -1\n",
    "                        EVDischargeStatus[sc,k,i,s+1] = -1\n",
    "\n",
    "                        activate_arc = (always_arc + congest_arc) if traffic[s] else (always_arc + normal_arc)\n",
    "                        EVArcStatus[sc,k,:,s] = -1\n",
    "\n",
    "    ##### replacing y_predict ######\n",
    "    corrected_y = []\n",
    "\n",
    "    for sc in range(nbScen):\n",
    "        for k in range(nbEV):\n",
    "            # for each EV get each attribute and order it based on EV number\n",
    "            for r in range(nbRoute):\n",
    "                for t in range(nbTime-1):\n",
    "                    corrected_y.append(EVArcStatus[sc,k,r,t])\n",
    "\n",
    "            for c in range(nbCS):\n",
    "                for t in range(nbTime):\n",
    "                    corrected_y.append(EVChargeStatus[sc,k,c,t])\n",
    "\n",
    "            for c in range(nbCS):\n",
    "                for t in range(nbTime):\n",
    "                    corrected_y.append(EVDischargeStatus[sc,k,c,t])\n",
    "\n",
    "    return corrected_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2592862\n",
      "Academic license - for non-commercial use only - expires 2025-11-29\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  2 :  1337603.8683535054\n",
      "Optimization value for model  2 :  9.122727632522583\n",
      "Optimization time for model  3 :  1371759.0463044154\n",
      "Optimization value for model  3 :  17.928706407546997\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  5 :  1386413.351296174\n",
      "Optimization value for model  5 :  32.38761234283447\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  8 :  1382461.781913377\n",
      "Optimization value for model  8 :  18.357588052749634\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  10 :  1410088.9767065076\n",
      "Optimization value for model  10 :  18.365204095840454\n",
      "Optimization time for model  11 :  1413940.279989934\n",
      "Optimization value for model  11 :  18.83163094520569\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  13 :  1271838.1610787255\n",
      "Optimization value for model  13 :  8.306628704071045\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  14 :  1389373.3162200926\n",
      "Optimization value for model  14 :  34.29404616355896\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  18 :  1483637.9799718051\n",
      "Optimization value for model  18 :  19.380428075790405\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  19 :  1390873.8004284904\n",
      "Optimization value for model  19 :  31.658788442611694\n",
      "Optimization time for model  20 :  1456435.6567696987\n",
      "Optimization value for model  20 :  17.23043441772461\n",
      "Optimization time for model  21 :  1366884.6829963126\n",
      "Optimization value for model  21 :  20.419293880462646\n",
      "Optimization time for model  22 :  1468218.8159549483\n",
      "Optimization value for model  22 :  21.57030487060547\n",
      "Optimization time for model  23 :  1467107.7714294663\n",
      "Optimization value for model  23 :  17.46396493911743\n",
      "Optimization time for model  24 :  1295281.3568891522\n",
      "Optimization value for model  24 :  8.222604990005493\n",
      "Optimization time for model  25 :  1351879.6868447626\n",
      "Optimization value for model  25 :  17.429401874542236\n",
      "Optimization time for model  26 :  1397065.5068175124\n",
      "Optimization value for model  26 :  19.24222421646118\n",
      "Optimization time for model  27 :  1466849.588395619\n",
      "Optimization value for model  27 :  22.336562395095825\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  28 :  1481616.3332578584\n",
      "Optimization value for model  28 :  32.255980014801025\n",
      "Optimization time for model  29 :  1308344.3785955\n",
      "Optimization value for model  29 :  17.480408430099487\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  30 :  1441781.5642513935\n",
      "Optimization value for model  30 :  36.36586356163025\n",
      "Optimization time for model  31 :  1414222.2620060463\n",
      "Optimization value for model  31 :  18.16514754295349\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  32 :  1417808.3679394645\n",
      "Optimization value for model  32 :  38.33119750022888\n",
      "Optimization time for model  33 :  1446483.4421121243\n",
      "Optimization value for model  33 :  20.199475288391113\n",
      "Optimization time for model  34 :  1411848.1617267258\n",
      "Optimization value for model  34 :  20.319831132888794\n",
      "Optimization time for model  35 :  1319736.8580319206\n",
      "Optimization value for model  35 :  11.245135068893433\n",
      "Optimization time for model  36 :  1416159.107097122\n",
      "Optimization value for model  36 :  20.76669192314148\n",
      "Optimization time for model  37 :  1311118.2698155825\n",
      "Optimization value for model  37 :  20.56405997276306\n",
      "Optimization time for model  38 :  1437918.3315462628\n",
      "Optimization value for model  38 :  21.51684331893921\n",
      "Optimization time for model  39 :  1439175.1075686584\n",
      "Optimization value for model  39 :  19.443408012390137\n",
      "Optimization time for model  40 :  1352860.057197307\n",
      "Optimization value for model  40 :  21.146761417388916\n",
      "Optimization time for model  41 :  1389130.8230505607\n",
      "Optimization value for model  41 :  21.283315658569336\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  42 :  1332318.307062018\n",
      "Optimization value for model  42 :  38.815117835998535\n",
      "Optimization time for model  43 :  1434985.5219625814\n",
      "Optimization value for model  43 :  20.049591779708862\n",
      "Optimization time for model  44 :  1454943.1769763816\n",
      "Optimization value for model  44 :  25.13339138031006\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  45 :  1414619.9292271752\n",
      "Optimization value for model  45 :  37.67675733566284\n",
      "Optimization time for model  46 :  1302840.4781489305\n",
      "Optimization value for model  46 :  9.242019653320312\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  47 :  1386824.5820349297\n",
      "Optimization value for model  47 :  36.01939535140991\n",
      "Optimization time for model  48 :  1459390.3828025896\n",
      "Optimization value for model  48 :  24.535484075546265\n",
      "Optimization time for model  49 :  1461606.511277863\n",
      "Optimization value for model  49 :  25.06950330734253\n",
      "Optimization time for model  50 :  1486095.1413220637\n",
      "Optimization value for model  50 :  24.53367805480957\n",
      "Optimization time for model  51 :  1462072.858453826\n",
      "Optimization value for model  51 :  21.1654531955719\n",
      "Optimization time for model  52 :  1458849.6704829445\n",
      "Optimization value for model  52 :  21.26675319671631\n",
      "Optimization time for model  53 :  1498541.1913791748\n",
      "Optimization value for model  53 :  24.57289409637451\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  54 :  1457949.483989996\n",
      "Optimization value for model  54 :  42.56187701225281\n",
      "Optimization time for model  55 :  1461793.3744742225\n",
      "Optimization value for model  55 :  22.668718576431274\n",
      "Optimization time for model  56 :  1443482.62139189\n",
      "Optimization value for model  56 :  23.533207654953003\n",
      "Optimization time for model  57 :  1306864.3780770353\n",
      "Optimization value for model  57 :  10.539200782775879\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  64 :  1565228.432938718\n",
      "Optimization value for model  64 :  25.910293579101562\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  67 :  1430072.16434671\n",
      "Optimization value for model  67 :  38.84523606300354\n",
      "Optimization time for model  68 :  1334029.532258443\n",
      "Optimization value for model  68 :  9.889740943908691\n",
      "Optimization time for model  69 :  1452127.7614539112\n",
      "Optimization value for model  69 :  22.25141191482544\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  71 :  1495660.428392654\n",
      "Optimization value for model  71 :  23.8155300617218\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  73 :  1490081.1216055334\n",
      "Optimization value for model  73 :  22.218106746673584\n",
      "Optimization time for model  74 :  1417186.9544243645\n",
      "Optimization value for model  74 :  20.931561708450317\n",
      "Optimization time for model  75 :  1498989.0752896797\n",
      "Optimization value for model  75 :  23.418785333633423\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  77 :  1470053.2185005324\n",
      "Optimization value for model  77 :  25.21727228164673\n",
      "Optimization time for model  78 :  1433868.9739256527\n",
      "Optimization value for model  78 :  25.65739393234253\n",
      "Optimization time for model  79 :  1319189.164382768\n",
      "Optimization value for model  79 :  10.657629489898682\n",
      "Optimization time for model  80 :  1437127.5131095652\n",
      "Optimization value for model  80 :  21.899704456329346\n",
      "Optimization time for model  81 :  1448849.4088190717\n",
      "Optimization value for model  81 :  25.00051498413086\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  82 :  1412614.9587567355\n",
      "Optimization value for model  82 :  45.528313875198364\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  83 :  1472446.5166935148\n",
      "Optimization value for model  83 :  41.9651665687561\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  85 :  1528355.917381256\n",
      "Optimization value for model  85 :  25.1235671043396\n",
      "Optimization time for model  86 :  1519409.139626226\n",
      "Optimization value for model  86 :  26.06358766555786\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  87 :  1452837.121359111\n",
      "Optimization value for model  87 :  44.07917857170105\n",
      "Optimization time for model  88 :  1485029.9668105412\n",
      "Optimization value for model  88 :  25.723190546035767\n",
      "Optimization time for model  89 :  1458246.8611152072\n",
      "Optimization value for model  89 :  23.649811267852783\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  90 :  1326830.4655542348\n",
      "Optimization value for model  90 :  19.08158302307129\n",
      "Optimization time for model  91 :  1519105.2058385382\n",
      "Optimization value for model  91 :  27.070035934448242\n",
      "Optimization time for model  92 :  1450684.6548035305\n",
      "Optimization value for model  92 :  26.12032675743103\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  93 :  1563350.0476428138\n",
      "Optimization value for model  93 :  44.89133286476135\n",
      "Optimization time for model  94 :  1460924.1969059445\n",
      "Optimization value for model  94 :  24.987114667892456\n",
      "Optimization time for model  95 :  1417336.7708118898\n",
      "Optimization value for model  95 :  27.83507490158081\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  96 :  1481547.9406209565\n",
      "Optimization value for model  96 :  52.2271773815155\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  97 :  1483711.7192454764\n",
      "Optimization value for model  97 :  47.03887891769409\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  98 :  1512665.0281179277\n",
      "Optimization value for model  98 :  51.77417707443237\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  99 :  1526812.678546346\n",
      "Optimization value for model  99 :  48.79966950416565\n",
      "Optimization time for model  100 :  1552005.2380503684\n",
      "Optimization value for model  100 :  29.423874616622925\n",
      "Optimization time for model  101 :  1246309.001673622\n",
      "Optimization value for model  101 :  11.057541608810425\n",
      "Optimization time for model  102 :  1569998.45876939\n",
      "Optimization value for model  102 :  29.12642002105713\n",
      "Optimization time for model  103 :  1511256.72711104\n",
      "Optimization value for model  103 :  25.25316548347473\n",
      "Optimization time for model  104 :  1556928.4123231946\n",
      "Optimization value for model  104 :  26.01760482788086\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  105 :  1485471.8669297192\n",
      "Optimization value for model  105 :  48.744415521621704\n",
      "Optimization time for model  106 :  1491839.592862832\n",
      "Optimization value for model  106 :  26.32175922393799\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  107 :  1434606.2828308432\n",
      "Optimization value for model  107 :  56.896531105041504\n",
      "Optimization time for model  108 :  1560182.8626593703\n",
      "Optimization value for model  108 :  26.35483193397522\n",
      "Optimization time for model  109 :  1499441.9384311337\n",
      "Optimization value for model  109 :  30.312073945999146\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  110 :  1511884.0572510078\n",
      "Optimization value for model  110 :  51.791386127471924\n",
      "Optimization time for model  111 :  1495098.853226758\n",
      "Optimization value for model  111 :  28.093944787979126\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  113 :  1359106.8932791066\n",
      "Optimization value for model  113 :  9.967218399047852\n",
      "Optimization time for model  114 :  1207436.9564382322\n",
      "Optimization value for model  114 :  11.242466449737549\n",
      "Optimization time for model  115 :  1399899.0169229966\n",
      "Optimization value for model  115 :  10.808660507202148\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  116 :  1255362.7190642795\n",
      "Optimization value for model  116 :  19.348360776901245\n",
      "Optimization time for model  117 :  1326933.2162893284\n",
      "Optimization value for model  117 :  10.859312295913696\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  126 :  1346283.478538079\n",
      "Optimization value for model  126 :  13.058455467224121\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  127 :  1346797.428212297\n",
      "Optimization value for model  127 :  23.71898627281189\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  128 :  1417761.3881288355\n",
      "Optimization value for model  128 :  22.57321310043335\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  130 :  1338583.3346861256\n",
      "Optimization value for model  130 :  15.462406635284424\n",
      "Optimization time for model  131 :  1342330.3018378746\n",
      "Optimization value for model  131 :  13.593663930892944\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  132 :  1391644.242926614\n",
      "Optimization value for model  132 :  26.43825936317444\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  133 :  1417965.7522540907\n",
      "Optimization value for model  133 :  27.50353479385376\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  135 :  1413690.135096825\n",
      "Optimization value for model  135 :  14.173750162124634\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  137 :  1370053.4481956535\n",
      "Optimization value for model  137 :  15.412946462631226\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  138 :  1329710.9392005247\n",
      "Optimization value for model  138 :  27.672340154647827\n",
      "Optimization time for model  139 :  1374519.7365354793\n",
      "Optimization value for model  139 :  16.63538098335266\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  140 :  1333584.8712668163\n",
      "Optimization value for model  140 :  28.827605962753296\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  141 :  1390542.2276059673\n",
      "Optimization value for model  141 :  29.90027379989624\n",
      "Optimization time for model  142 :  1385603.29345894\n",
      "Optimization value for model  142 :  19.134576559066772\n",
      "Optimization time for model  143 :  1331779.986844961\n",
      "Optimization value for model  143 :  15.027202129364014\n",
      "Optimization time for model  144 :  1354769.1392581167\n",
      "Optimization value for model  144 :  15.208668231964111\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  150 :  1395997.7115670429\n",
      "Optimization value for model  150 :  16.612945556640625\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  152 :  1404181.436684784\n",
      "Optimization value for model  152 :  30.960721015930176\n",
      "Optimization time for model  153 :  1346934.6641082184\n",
      "Optimization value for model  153 :  18.042652368545532\n",
      "Optimization time for model  154 :  1461207.2952497092\n",
      "Optimization value for model  154 :  17.89600968360901\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  155 :  1397797.658664668\n",
      "Optimization value for model  155 :  32.29519462585449\n",
      "Optimization time for model  156 :  1268349.6743918979\n",
      "Optimization value for model  156 :  6.620075702667236\n",
      "Optimization time for model  157 :  1437359.919089852\n",
      "Optimization value for model  157 :  17.347410440444946\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  158 :  1453280.7323135897\n",
      "Optimization value for model  158 :  33.424163579940796\n",
      "Optimization time for model  159 :  1414599.7478519427\n",
      "Optimization value for model  159 :  19.297293424606323\n",
      "Optimization time for model  160 :  1404337.3212241482\n",
      "Optimization value for model  160 :  20.6962251663208\n",
      "Optimization time for model  161 :  1403571.4067760606\n",
      "Optimization value for model  161 :  18.71648073196411\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  162 :  1372368.4068161258\n",
      "Optimization value for model  162 :  46.403409481048584\n",
      "Optimization time for model  163 :  1423817.3627716117\n",
      "Optimization value for model  163 :  20.175851345062256\n",
      "Optimization time for model  164 :  1429058.6293240678\n",
      "Optimization value for model  164 :  19.700519323349\n",
      "Optimization time for model  165 :  1463309.417767793\n",
      "Optimization value for model  165 :  22.08414053916931\n",
      "Optimization time for model  166 :  1461680.276981035\n",
      "Optimization value for model  166 :  22.93292212486267\n",
      "Optimization time for model  167 :  1302771.4931893556\n",
      "Optimization value for model  167 :  7.3921217918396\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  168 :  1380657.8642373309\n",
      "Optimization value for model  168 :  49.55393123626709\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  169 :  1466756.2942976127\n",
      "Optimization value for model  169 :  42.71217632293701\n",
      "Optimization time for model  170 :  1447774.8205247954\n",
      "Optimization value for model  170 :  22.069803953170776\n",
      "Optimization time for model  171 :  1376770.6403620986\n",
      "Optimization value for model  171 :  22.134127140045166\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  172 :  1422472.2786447485\n",
      "Optimization value for model  172 :  40.066744327545166\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  178 :  1304103.0394645622\n",
      "Optimization value for model  178 :  7.321057081222534\n",
      "infeasible, reoptimising\n",
      "infeasible\n",
      "Optimization time for model  180 :  1512768.4782748607\n",
      "Optimization value for model  180 :  25.08370327949524\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  181 :  1490323.2985695833\n",
      "Optimization value for model  181 :  43.635570764541626\n",
      "Optimization time for model  182 :  1438710.7421372198\n",
      "Optimization value for model  182 :  23.71864914894104\n",
      "Optimization time for model  183 :  1434879.6298710974\n",
      "Optimization value for model  183 :  23.151237726211548\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  184 :  1511445.6283220807\n",
      "Optimization value for model  184 :  44.215975284576416\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  185 :  1474173.3567427285\n",
      "Optimization value for model  185 :  42.58663845062256\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  186 :  1476433.0994053485\n",
      "Optimization value for model  186 :  45.70270109176636\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  187 :  1563040.60026138\n",
      "Optimization value for model  187 :  47.603604793548584\n",
      "Optimization time for model  188 :  1480888.110731266\n",
      "Optimization value for model  188 :  28.527222871780396\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  189 :  1338010.62703773\n",
      "Optimization value for model  189 :  13.795221328735352\n",
      "Optimization time for model  190 :  1421139.9771829972\n",
      "Optimization value for model  190 :  27.209995985031128\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  191 :  1459002.2234590133\n",
      "Optimization value for model  191 :  50.600454330444336\n",
      "Optimization time for model  192 :  1441948.5587028458\n",
      "Optimization value for model  192 :  28.273481845855713\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  193 :  1426736.2964911247\n",
      "Optimization value for model  193 :  48.14409804344177\n",
      "Optimization time for model  194 :  1469649.536531751\n",
      "Optimization value for model  194 :  40.7159583568573\n",
      "Optimization time for model  195 :  1575977.1649858572\n",
      "Optimization value for model  195 :  28.338342428207397\n",
      "Optimization time for model  196 :  1506991.5444405472\n",
      "Optimization value for model  196 :  30.503377199172974\n",
      "infeasible, reoptimising\n",
      "Optimization time for model  197 :  1443922.3798664764\n",
      "Optimization value for model  197 :  48.35344219207764\n",
      "Optimization time for model  198 :  1516945.2794653082\n",
      "Optimization value for model  198 :  28.405895471572876\n",
      "Optimization time for model  199 :  1411233.4518695958\n",
      "Optimization value for model  199 :  25.07080340385437\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "gurobi_env = gb.Env()\n",
    "gurobi_env.setParam(\"OutputFlag\", 0)\n",
    "\n",
    "# loop through all test models and calculate average optimization time\n",
    "opt_time_feas = []\n",
    "opt_val_feas = []\n",
    "opt_ones_feas = []\n",
    "opt_utilized_feas = []\n",
    "for i, x in enumerate(model_test):\n",
    "    # if i == 28:\n",
    "\n",
    "    path = os.path.join(os.getcwd(), \"dataGeneration/model_test\")\n",
    "\n",
    "    model = gb.read(os.path.join(path, f\"coordination_{x}.mps\"), env=gurobi_env)\n",
    "    model.setParam(\"OutputFlag\", 0)\n",
    "    model.setParam(\"TimeLimit\", 120*60)\n",
    "\n",
    "    ################# timing the first code block #####################\n",
    "    start = time.time()\n",
    "\n",
    "    # deep learning prediciton\n",
    "    output_append = torch.tensor([], device=device)\n",
    "    gt_append = torch.tensor([], device=device)\n",
    "\n",
    "    for s in range(nbScen):\n",
    "        inputs = torch.tensor(np.expand_dims(test_dataset.X[i][s], axis=0), dtype=torch.float32) \n",
    "        inputs = inputs.to(device)    \n",
    "        outputs = net(inputs) \n",
    "\n",
    "        # extract correct amount of binary before concat\n",
    "        nbEV = np.max(schedule_test[i][:,0]) + 1\n",
    "        outs = outputs[:,0:var_per_EV*nbEV]\n",
    "        gts = torch.tensor(y_test[i,s,0:var_per_EV*nbEV], device=device).reshape(1,-1)\n",
    "\n",
    "        output_append = torch.concat((output_append, outs),dim=1)\n",
    "        gt_append = torch.concat((gt_append, gts),dim=1)\n",
    "\n",
    "    output_append = output_append.reshape(-1,)\n",
    "    gt_append = gt_append.reshape(-1,)\n",
    "\n",
    "    ################## end #########################\n",
    "\n",
    "    y_pred_binary =  (output_append).reshape(-1,).cpu().detach().numpy()\n",
    "    # y_pred_binary = gt_append.reshape(-1,).cpu().detach().numpy()\n",
    "\n",
    "    modelVars = model.getVars()\n",
    "\n",
    "    # get correct amount of index\n",
    "    bin_id = index_test[i][0:var_per_EV*nbEV*nbScen].reshape(-1,)\n",
    "\n",
    "    one_threshold = (np.mean(mean_one))\n",
    "    zero_threshold = (1-np.mean(mean_zero))\n",
    "\n",
    "    # use equality constraint from here on\n",
    "    for j in range(len(y_pred_binary)):\n",
    "        if (y_pred_binary[j] >= one_threshold or y_pred_binary[j] <= zero_threshold):\n",
    "            modelVars[bin_id[j]].setAttr(\"LB\", round(y_pred_binary[j]))\n",
    "            modelVars[bin_id[j]].setAttr(\"UB\", round(y_pred_binary[j]))\n",
    "            \n",
    "    end = time.time()\n",
    "    runtime1 = end - start\n",
    "\n",
    "    opt_ones_feas.append(np.count_nonzero(y_pred_binary >= one_threshold))\n",
    "    opt_utilized_feas.append(np.count_nonzero(y_pred_binary >= one_threshold)+  np.count_nonzero(y_pred_binary <= zero_threshold))\n",
    "\n",
    "    ################# timing the second code block #####################\n",
    "    start = time.time()\n",
    "\n",
    "    model.optimize()\n",
    "\n",
    "    end = time.time()\n",
    "    runtime2 = end - start\n",
    "    runtime = runtime1 + runtime2\n",
    "    ################## end #########################\n",
    "    \n",
    "    try:\n",
    "        print(\"Optimization time for model \", i, \": \", model.ObjVal)\n",
    "        print(\"Optimization value for model \", i, \": \", runtime)\n",
    "        opt_time_feas.append(runtime)\n",
    "        opt_val_feas.append(model.ObjVal) \n",
    "\n",
    "    except:\n",
    "        print(\"infeasible, reoptimising\")\n",
    "\n",
    "        model.dispose()\n",
    "\n",
    "        ###### reset model and re-fix the values\n",
    "        model = gb.read(os.path.join(path, f\"coordination_{x}.mps\"), env=gurobi_env)\n",
    "        model.setParam(\"OutputFlag\", 0)\n",
    "        model.setParam(\"TimeLimit\", 120*60)\n",
    "\n",
    "        ################# timing the code block #####################\n",
    "        start = time.time()\n",
    "\n",
    "        modelVars = model.getVars()\n",
    "\n",
    "        # get correct amount of index\n",
    "        bin_id = index_test[i][0:var_per_EV*nbEV*nbScen].reshape(-1,)\n",
    "\n",
    "        one_threshold = (np.mean(mean_one)) + 0.1\n",
    "        zero_threshold = (1-np.mean(mean_zero))\n",
    "\n",
    "        # use equality constraint from here on\n",
    "        for j in range(len(y_pred_binary)):\n",
    "            if (y_pred_binary[j] >= one_threshold or y_pred_binary[j] <= zero_threshold):\n",
    "                modelVars[bin_id[j]].setAttr(\"LB\", round(y_pred_binary[j]))\n",
    "                modelVars[bin_id[j]].setAttr(\"UB\", round(y_pred_binary[j]))\n",
    "\n",
    "        # y_pred_binary = np.where((y_pred_binary >= zero_threshold) & (y_pred_binary <= one_threshold), -1, np.round(y_pred_binary))\n",
    "        # y_pred_binary = solution_check(y_pred_binary, model, bin_id, schedule_test[i])\n",
    "\n",
    "        # # use equality constraint from here on\n",
    "        # for j in range(len(y_pred_binary)):\n",
    "        #     # if (y_pred_binary[j] >= one_threshold or y_pred_binary[j] <= zero_threshold):\n",
    "        #     if (y_pred_binary[j] >= 0):\n",
    "        #         modelVars[bin_id[j]].setAttr(\"LB\", round(y_pred_binary[j]))\n",
    "        #         modelVars[bin_id[j]].setAttr(\"UB\", round(y_pred_binary[j]))\n",
    "                \n",
    "        end = time.time()\n",
    "        runtime3 = end - start\n",
    "        \n",
    "        opt_ones_feas.append(np.count_nonzero(y_pred_binary >= one_threshold))\n",
    "        opt_utilized_feas.append(np.count_nonzero(y_pred_binary >= one_threshold)+  np.count_nonzero(y_pred_binary <= zero_threshold))\n",
    "\n",
    "        ################# timing the second code block #####################\n",
    "        start = time.time()\n",
    "\n",
    "        model.optimize()\n",
    "\n",
    "        end = time.time()\n",
    "        runtime4 = end - start\n",
    "        runtime = runtime + runtime3 + runtime4 \n",
    "\n",
    "        try:\n",
    "            print(\"Optimization time for model \", i, \": \", model.ObjVal)\n",
    "            print(\"Optimization value for model \", i, \": \", runtime)\n",
    "            opt_time_feas.append(runtime)\n",
    "            opt_val_feas.append(model.ObjVal) \n",
    "        except:\n",
    "            print('infeasible')\n",
    "            opt_time_feas.append(0)\n",
    "            opt_val_feas.append(0) \n",
    "\n",
    "    \n",
    "    model.dispose()\n",
    "    # break\n",
    "    # else:\n",
    "    #     continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dict_feas = {\n",
    "    \"opt_time\": opt_time_feas,\n",
    "    \"opt_val\": opt_val_feas,\n",
    "    \"opt_ones\": opt_ones_feas,\n",
    "    \"opt_utilized\": opt_utilized_feas\n",
    "}\n",
    "\n",
    "result_path = os.path.join(os.getcwd(), f\"Results\")\n",
    "with open(os.path.join(result_path, f\"CNN_1D_{interval}_test_opt_feas.pkl\"), 'wb') as f:\n",
    "    pickle.dump(opt_dict_feas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, f\"CNN_1D_{interval}_test_opt_feas.pkl\"), 'rb') as f:\n",
    "    opt_dict_feas = pickle.load(f)\n",
    "\n",
    "opt_time_feas = opt_dict_feas[\"opt_time\"]\n",
    "opt_val_feas = opt_dict_feas[\"opt_val\"]\n",
    "opt_ones_feas = opt_dict_feas[\"opt_ones\"]\n",
    "opt_utilized_feas = opt_dict_feas[\"opt_utilized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average optimization time:  20.003699326515196\n",
      "Average optimization value:  1096831.135578554\n",
      "Number of feasible model 200\n",
      "Number of ones:  [3401, 2719, 3548, 2812, 3250, 10038, 11866, 9839, 11931, 9560, 13477, 11133, 9888, 7638, 10040, 9860, 7892, 11720, 9829, 11664, 9280, 3820, 11429, 9117, 12329, 10294, 9771, 7581, 9103, 7322, 10662, 13538, 11115, 10445, 9965, 10960, 12608, 3742, 10628, 11570, 11404, 13659, 10996, 9705, 10810, 8221, 10491, 12417, 9805, 12311, 12352, 3756, 11697, 11275, 11434, 11073, 11476, 12828, 14137, 11245, 14720, 14157, 11297, 8829, 4171, 16202, 13192, 12720, 12772, 12605, 12465, 12449, 12994, 15771, 13038, 15157, 13646, 3792, 14163, 11003, 17679, 14385, 16041, 13499, 16270, 13264, 13817, 10921, 15729, 12654, 15063, 16362, 13520, 16366, 13494, 18050, 14730, 4796, 15954, 12950, 9965, 15634, 17027, 13638, 13226, 18400, 16867, 15142, 11798, 16667, 16636, 5630, 17658, 16633, 14431, 11005, 17664, 13891, 14496, 11368, 15643, 15581, 18273, 14321, 18369, 19534, 5143, 3951, 17281, 19271, 18272, 14235, 19562, 19161, 17692, 13852, 21022, 17299, 19837, 15863, 18664, 14201, 16156, 5223, 16042, 19938, 19991, 20350, 16425, 16205, 17987, 14256, 18555, 19088, 20329, 16154, 17310, 3087, 2417, 6182, 5749, 4843, 6712, 5523, 7760, 7677, 6029, 7229, 5745, 7276, 5810, 9197, 7675, 6594, 5053, 2955, 2198, 7078, 5522, 7042, 5475, 8946, 8203, 6301, 6662, 5122, 6982, 5385, 8187, 9091, 9118, 7040, 9389, 7439, 4122, 3274, 10763, 9615, 7331, 8930, 9466, 7507, 9516, 10215, 8054, 11140, 8828, 9669, 10155, 12773, 4209, 3400, 9391, 7544, 12553, 10515, 10128, 7659, 12331, 10288, 12153, 11636, 9300, 13477, 11077, 12119, 12090, 13574, 11089, 3421, 10204, 13859, 11101, 12181, 12640, 10757, 11876, 9391, 14538, 14182, 12364, 12246, 3583, 14440, 11563, 12843, 9921, 12442, 14375, 14207, 11196, 16320, 13692, 12913, 9905, 15920, 12603, 13533, 10451, 13626, 10481, 3786, 12888, 10160, 14033, 13399, 10330, 13603, 15060, 14368, 11001, 17727, 14026, 18363, 14642, 19249, 15564, 14135, 3389, 2529, 17067, 19623, 15701, 17153, 20027, 15748, 16004, 15837, 16105, 18573, 14496, 17593, 20623]\n",
      "Number of variable utilized  [765426, 764744, 775841, 775105, 1012004, 2250424, 2229549, 2227522, 2203987, 2201616, 2248584, 2246240, 2270472, 2268222, 2289450, 2283426, 2281458, 2274692, 2306937, 2304928, 2302544, 1060549, 2312132, 2309820, 2351731, 2349696, 2345118, 2342928, 2417752, 2415971, 2433975, 2436116, 2433693, 2428960, 2456020, 2469121, 2513287, 1051154, 2511549, 2491700, 2542169, 2540479, 2537816, 2557224, 2569992, 2567403, 2628194, 2621235, 2618623, 2595194, 2638892, 1124638, 2638040, 2661693, 2701446, 2698173, 2704676, 2714014, 2674002, 2671110, 2671181, 2793653, 2767935, 2765467, 1142359, 2795126, 2792116, 2815488, 2814853, 2801269, 2881778, 2881559, 2875359, 2897447, 2894714, 2886255, 2879701, 1154998, 2952516, 2949356, 2964512, 2961218, 2961896, 2959354, 2968507, 2965501, 3030989, 3028093, 3002905, 2999830, 3013268, 3049513, 3046671, 3047710, 3044838, 3043496, 3040176, 1211275, 3077227, 3060473, 3057488, 3069886, 3169993, 3166604, 3177042, 3157512, 3176601, 3164160, 3160816, 3207721, 3222428, 1204864, 3242169, 3218490, 3239542, 3236116, 3271197, 3267424, 3249735, 3246607, 3357732, 3359000, 3339145, 3335193, 3319575, 3342833, 1249390, 1248198, 3364485, 3362906, 3398770, 3394733, 3397526, 3400457, 3471281, 3467441, 3438975, 3435252, 3416783, 3412809, 3467806, 3463343, 3501976, 1299617, 3521784, 3558529, 3539276, 3527140, 3523215, 3572474, 3558218, 3554487, 3569410, 3610411, 3606447, 3602272, 3608089, 797480, 796810, 1314912, 1365626, 1342992, 1390507, 1389318, 1422570, 1500735, 1499087, 1510863, 1509379, 1546406, 1544940, 1534483, 1532961, 1560304, 1558763, 788891, 788134, 1620623, 1619067, 1618863, 1617296, 1677665, 1744677, 1742775, 1711306, 1709766, 1770192, 1768595, 1795286, 1780310, 1884561, 1882483, 1856831, 1854881, 840715, 839867, 1893714, 1928900, 1926616, 1924408, 1980227, 1978268, 2040646, 2052425, 2050264, 2079585, 2077273, 2123536, 2139355, 2167065, 881816, 881007, 2228461, 2226614, 2237952, 2235914, 2249039, 2246570, 2271378, 2269335, 2308914, 2316618, 2314282, 2360541, 2358141, 2430567, 2455538, 2470957, 2468472, 868421, 2510008, 2541936, 2539178, 2538562, 2601637, 2605807, 2648795, 2646310, 2635581, 2672784, 2716700, 2807452, 942069, 2783346, 2780469, 2810808, 2807886, 2882463, 2859724, 2860443, 2857432, 2962346, 2959718, 2940876, 2937868, 3012345, 3009028, 2992006, 2988924, 3030221, 3027076, 978718, 3101473, 3098745, 3064749, 3128773, 3125704, 3213727, 3177214, 3196515, 3193148, 3274250, 3270549, 3237238, 3233517, 3308886, 3305201, 3327567, 973169, 972309, 3364270, 3380447, 3376525, 3401752, 3452523, 3448244, 3527502, 3515822, 3558352, 3589710, 3585633, 3560270, 3645712]\n"
     ]
    }
   ],
   "source": [
    "# flatten opt_time\n",
    "opt_time_feas_mean = np.mean(opt_time_feas)\n",
    "print(\"Average optimization time: \", np.mean(opt_time_feas))\n",
    "# flatten opt_time\n",
    "opt_val_feas_mean = np.mean(opt_val_feas)\n",
    "print(\"Average optimization value: \", np.mean(opt_val_feas))\n",
    "print(\"Number of feasible model\", len(opt_time_feas))\n",
    "print(\"Number of ones: \", opt_ones_feas)\n",
    "print(\"Number of variable utilized \", opt_utilized_feas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate time sped up by and optimality difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time sped up for threshold & feasibility check: 99.64259926909645 %, 99.59376415540153 %\n",
      "Optimality Loss for threshold & feasibility cheack: 1.0485543958206813 %, 0.2899727780725074 %\n",
      "Feasible model for threshold & feasibility cheack: 74.5 %, 95.5 %\n"
     ]
    }
   ],
   "source": [
    "speedup_time_thres = 1 - (opt_time_thres_mean/opt_time_baseline)\n",
    "optimality_loss_thres = (opt_val_thres_mean - opt_val_baseline) / opt_val_baseline\n",
    "feasible_model_thres = len(opt_time_thres) / len(model_test) * 100\n",
    "# ones_utilized_thres = np.array(opt_ones_thres) / np.array(opt_ones) *100\n",
    "# prediction_utilized_thres = np.array(opt_utilized_thres) / len(index_test[0]) *100\n",
    "\n",
    "speedup_time_feas = 1 - (opt_time_feas_mean/opt_time_baseline)\n",
    "optimality_loss_feas = (opt_val_feas_mean - opt_val_baseline) / opt_val_baseline\n",
    "feasible_model_feas = len(opt_time_feas) / len(model_test) * 100\n",
    "# ones_utilized_feas = np.array(opt_ones_feas) / np.array(opt_ones) *100\n",
    "# prediction_utilized_feas = np.array(opt_utilized_feas) / len(index_test[0]) *100\n",
    "\n",
    "print(f\"Time sped up for threshold & feasibility check: {speedup_time_thres*100} %, {speedup_time_feas*100} %\")\n",
    "print(f\"Optimality Loss for threshold & feasibility cheack: {optimality_loss_thres*100} %, {optimality_loss_feas*100} %\")\n",
    "print(f\"Feasible model for threshold & feasibility cheack: {feasible_model_thres} %, {feasible_model_feas} %\")\n",
    "# print(f\"Average Number ones used for threshold & feasibility cheack: {np.mean(ones_utilized_thres)} %, {np.mean(ones_utilized_feas)} %\")\n",
    "# print(f\"Number of prediction utilized for threshold & feasibility cheack: {np.mean(prediction_utilized_thres)} %, {np.mean(prediction_utilized_feas)} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7559388059411475\n",
      "3.913039588430057e-06\n"
     ]
    }
   ],
   "source": [
    "opt_time_feas_arr = np.array(opt_time_feas)\n",
    "opt_val_feas_arr = np.array(opt_val_feas)\n",
    "opt_time_arr = np.array(opt_time)\n",
    "opt_val_arr = np.array(opt_val)\n",
    "\n",
    "inf_id = np.where(opt_time_feas_arr == 0.0)\n",
    "\n",
    "opt_time_feas_arr[inf_id] = opt_time_arr[inf_id]\n",
    "opt_val_feas_arr[inf_id] = opt_val_arr[inf_id]\n",
    "\n",
    "spd_up = 1-(np.array(opt_time_feas_arr)/np.array(opt_time_arr))\n",
    "opt_loss = ((np.array(opt_val_feas_arr) - np.array(opt_val_arr))/np.array(opt_val_arr))\n",
    "\n",
    "print(np.mean(spd_up))\n",
    "print(np.mean(opt_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
